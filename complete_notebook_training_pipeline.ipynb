{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-19T19:12:44.516498Z",
     "iopub.status.busy": "2021-10-19T19:12:44.515721Z",
     "iopub.status.idle": "2021-10-19T19:12:48.012486Z",
     "shell.execute_reply": "2021-10-19T19:12:48.010651Z",
     "shell.execute_reply.started": "2021-10-19T19:12:44.516401Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pprint\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:12:51.542188Z",
     "iopub.status.busy": "2021-10-19T19:12:51.541917Z",
     "iopub.status.idle": "2021-10-19T19:12:55.892782Z",
     "shell.execute_reply": "2021-10-19T19:12:55.891741Z",
     "shell.execute_reply.started": "2021-10-19T19:12:51.542157Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load train\n",
    "train = pd.read_csv(\"./vpp_data/train.csv\")\n",
    "test = pd.read_csv('./vpp_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data...\n",
      "\n",
      "Step-1...Completed\n",
      "Step-2...Completed\n",
      "Step-3...Completed\n",
      "Step-4...Completed\n",
      "Step-5...Completed\n",
      "Step-6...Completed\n",
      "Step-7...Completed\n",
      "Step-8...Completed\n",
      "\n",
      "Test data...\n",
      "\n",
      "Step-1...Completed\n",
      "Step-2...Completed\n",
      "Step-3...Completed\n",
      "Step-4...Completed\n",
      "Step-5...Completed\n",
      "Step-6...Completed\n",
      "Step-7...Completed\n",
      "Step-8...Completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_features(df):\n",
    "    df['cross']= df['u_in'] * df['u_out']\n",
    "    df['cross2']= df['time_step'] * df['u_out']\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "    print(\"Step-1...Completed\")\n",
    "    \n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "    print(\"Step-2...Completed\")\n",
    "    \n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_in__mean'] = df.groupby(['breath_id'])['u_in'].transform('mean')\n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    print(\"Step-3...Completed\")\n",
    "    \n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    print(\"Step-4...Completed\")\n",
    "    \n",
    "    df['one'] = 1\n",
    "    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n",
    "    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n",
    "    \n",
    "    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n",
    "    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n",
    "    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n",
    "    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n",
    "    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n",
    "    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n",
    "    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n",
    "    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']\n",
    "    print(\"Step-5...Completed\")\n",
    "    \n",
    "    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n",
    "    df[[\"15_in_sum\",\"15_in_min\",\"15_in_max\",\"15_in_mean\"]] = (df\\\n",
    "                                                              .groupby('breath_id')['u_in']\\\n",
    "                                                              .rolling(window=15,min_periods=1)\\\n",
    "                                                              .agg({\"15_in_sum\":\"sum\",\n",
    "                                                                    \"15_in_min\":\"min\",\n",
    "                                                                    \"15_in_max\":\"max\",\n",
    "                                                                    \"15_in_mean\":\"mean\"})\\\n",
    "                                                               .reset_index(level=0,drop=True))\n",
    "    print(\"Step-6...Completed\")\n",
    "    \n",
    "    df['u_in_lagback_diff1'] = df['u_in'] - df['u_in_lag_back1']\n",
    "    df['u_out_lagback_diff1'] = df['u_out'] - df['u_out_lag_back1']\n",
    "    df['u_in_lagback_diff2'] = df['u_in'] - df['u_in_lag_back2']\n",
    "    df['u_out_lagback_diff2'] = df['u_out'] - df['u_out_lag_back2']\n",
    "    print(\"Step-7...Completed\")\n",
    "    \n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
    "    df = pd.get_dummies(df)\n",
    "    print(\"Step-8...Completed\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Train data...\\n\")\n",
    "train_df = create_features(train)\n",
    "\n",
    "print(\"\\nTest data...\\n\")\n",
    "test_df = create_features(test)\n",
    "\n",
    "del train\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:12:55.894932Z",
     "iopub.status.busy": "2021-10-19T19:12:55.89466Z",
     "iopub.status.idle": "2021-10-19T19:14:02.012769Z",
     "shell.execute_reply": "2021-10-19T19:14:02.011963Z",
     "shell.execute_reply.started": "2021-10-19T19:12:55.894896Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_features(dataframe, list_of_features = ['u_in']):\n",
    "    \n",
    "    # u_in cumsum\n",
    "    dataframe['u_in_cumsum'] = dataframe.groupby('breath_id')['u_in'].cumsum()\n",
    "    \n",
    "    # u_in shift change \n",
    "    for lag in np.arange(1, 5, 1):\n",
    "        dataframe[f'u_in_lag_fwrd{lag}'] = dataframe.groupby('breath_id')['u_in'].shift(lag).fillna(0)\n",
    "        dataframe[f'u_in_lag_back{lag}'] = dataframe.groupby('breath_id')['u_in'].shift(int(-lag)).fillna(0)\n",
    "        \n",
    "    # time diff\n",
    "    dataframe['time_diff'] = dataframe.groupby('breath_id')['time_step'].diff(1).fillna(0)\n",
    "    dataframe['time_diff_2'] = dataframe.groupby('breath_id')['time_step'].diff(2).fillna(0)\n",
    "    dataframe['time_diff_3'] = dataframe.groupby('breath_id')['time_step'].diff(3).fillna(0)\n",
    "    dataframe['time_diff_4'] = dataframe.groupby('breath_id')['time_step'].diff(4).fillna(0)\n",
    "    dataframe['time_diff_5'] = dataframe.groupby('breath_id')['time_step'].diff(5).fillna(0)\n",
    "\n",
    "    # u_in area\n",
    "    dataframe['area'] = dataframe['time_step'] * dataframe['u_in']\n",
    "    dataframe['area_cumsum'] = dataframe.groupby('breath_id')['area'].cumsum()\n",
    "    # add rectangle method\n",
    "    dataframe['auc_u_in'] = dataframe['time_diff'] * dataframe['u_in']\n",
    "    dataframe['auc_u_in_cumsum'] = dataframe.groupby('breath_id')['auc_u_in'].cumsum()\n",
    "    \n",
    "    dataframe['u_in_cumsum'] = dataframe.groupby('breath_id')['u_in'].cumsum()\n",
    "    \n",
    "    for feature in list_of_features:\n",
    "    \n",
    "        grouped_dataframe = dataframe.groupby('breath_id')[feature].agg([max, min, np.mean, np.median])    \n",
    "        \n",
    "        dataframe = dataframe.merge(\n",
    "            grouped_dataframe, \n",
    "            how='left', \n",
    "            on='breath_id'\n",
    "        )\n",
    "        \n",
    "        dataframe = dataframe.rename(\n",
    "            columns = {\n",
    "                'max':feature+'_max', \n",
    "                'min':feature+'_min', \n",
    "                'mean':feature+'_mean', \n",
    "                'median':feature+'_median'\n",
    "            }\n",
    "        )\n",
    "    \n",
    "        dataframe[f'{feature}_range'] = (dataframe[f'{feature}_max'] - dataframe[f'{feature}_min']).apply(lambda x: max(0,x))\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "#train_df = create_features(train_df)\n",
    "#test_df = create_features(test_df)\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:02.015496Z",
     "iopub.status.busy": "2021-10-19T19:14:02.013929Z",
     "iopub.status.idle": "2021-10-19T19:14:48.603421Z",
     "shell.execute_reply": "2021-10-19T19:14:48.602673Z",
     "shell.execute_reply.started": "2021-10-19T19:14:02.015454Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html\n",
    "# robustscaler is great to take into account outliers\n",
    "\n",
    "RS = RobustScaler()\n",
    "\n",
    "# not including u_out as it is a boolean\n",
    "columns_to_scale = [elm for elm in train_df.columns if elm not in ['id', 'breath_id', 'time_step', 'pressure', 'u_out']]\n",
    "train_df[columns_to_scale] = RS.fit_transform(train_df[columns_to_scale])\n",
    "\n",
    "test_df['pressure'] = 0\n",
    "test_df[columns_to_scale] = RS.transform(test_df[columns_to_scale])\n",
    "\n",
    "test_df = test_df.drop('pressure', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:48.606484Z",
     "iopub.status.busy": "2021-10-19T19:14:48.605379Z",
     "iopub.status.idle": "2021-10-19T19:14:52.806983Z",
     "shell.execute_reply": "2021-10-19T19:14:52.806266Z",
     "shell.execute_reply.started": "2021-10-19T19:14:48.60644Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T18:40:44.85471Z",
     "iopub.status.busy": "2021-10-19T18:40:44.853796Z",
     "iopub.status.idle": "2021-10-19T18:40:44.861866Z",
     "shell.execute_reply": "2021-10-19T18:40:44.861065Z",
     "shell.execute_reply.started": "2021-10-19T18:40:44.854673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'breath_id', 'time_step', 'u_in', 'u_out', 'pressure', 'cross',\n",
       "       'cross2', 'area', 'time_step_cumsum', 'u_in_cumsum', 'u_in_lag1',\n",
       "       'u_out_lag1', 'u_in_lag_back1', 'u_out_lag_back1', 'u_in_lag2',\n",
       "       'u_out_lag2', 'u_in_lag_back2', 'u_out_lag_back2', 'u_in_lag3',\n",
       "       'u_out_lag3', 'u_in_lag_back3', 'u_out_lag_back3', 'u_in_lag4',\n",
       "       'u_out_lag4', 'u_in_lag_back4', 'u_out_lag_back4',\n",
       "       'breath_id__u_in__max', 'breath_id__u_in__mean',\n",
       "       'breath_id__u_in__diffmax', 'breath_id__u_in__diffmean', 'u_in_diff1',\n",
       "       'u_out_diff1', 'u_in_diff2', 'u_out_diff2', 'u_in_diff3', 'u_out_diff3',\n",
       "       'u_in_diff4', 'u_out_diff4', 'one', 'count', 'u_in_cummean',\n",
       "       'breath_id_lag', 'breath_id_lag2', 'breath_id_lagsame',\n",
       "       'breath_id_lag2same', 'breath_id__u_in_lag', 'breath_id__u_in_lag2',\n",
       "       'time_step_diff', '15_in_sum', '15_in_min', '15_in_max', '15_in_mean',\n",
       "       'u_in_lagback_diff1', 'u_out_lagback_diff1', 'u_in_lagback_diff2',\n",
       "       'u_out_lagback_diff2', 'R_20', 'R_5', 'R_50', 'C_10', 'C_20', 'C_50',\n",
       "       'R__C_20__10', 'R__C_20__20', 'R__C_20__50', 'R__C_50__10',\n",
       "       'R__C_50__20', 'R__C_50__50', 'R__C_5__10', 'R__C_5__20', 'R__C_5__50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns\n",
    "\n",
    "# ['id', 'breath_id', 'R', 'C', 'time_step', 'u_in', 'u_out', 'pressure',\n",
    "#        'u_in_cumsum', 'u_in_lag_fwrd1', 'u_in_lag_back1', 'u_in_lag_fwrd2',\n",
    "#        'u_in_lag_back2', 'u_in_lag_fwrd3', 'u_in_lag_back3', 'u_in_lag_fwrd4',\n",
    "#        'u_in_lag_back4', 'time_diff', 'time_diff_2', 'time_diff_3',\n",
    "#        'time_diff_4', 'time_diff_5', 'area', 'u_in_max', 'u_in_min',\n",
    "#        'u_in_mean', 'u_in_median', 'u_in_range', 'time_step_max',\n",
    "#        'time_step_min', 'time_step_mean', 'time_step_median',\n",
    "#        'time_step_range', 'RC', 'R/C', 'C/R', 'log_RC', 'log_R/C', 'log_C/R',\n",
    "#        'exp_R/C', 'exp_C/R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:52.808716Z",
     "iopub.status.busy": "2021-10-19T19:14:52.808447Z",
     "iopub.status.idle": "2021-10-19T19:14:52.832759Z",
     "shell.execute_reply": "2021-10-19T19:14:52.831817Z",
     "shell.execute_reply.started": "2021-10-19T19:14:52.808682Z"
    }
   },
   "outputs": [],
   "source": [
    "class VPPDataLoader(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        \n",
    "        if \"pressure\" not in dataframe.columns:\n",
    "            dataframe['pressure'] = 0\n",
    "            \n",
    "        # aggregate data and store features as list\n",
    "        self.df_grouped = dataframe.groupby('breath_id').agg(list).reset_index()\n",
    "        self._preprocess()\n",
    "        \n",
    "    def _preprocess(self):\n",
    "        self.pressures = np.array(self.df_grouped['pressure'].values.tolist())\n",
    "        \n",
    "        u_ins = np.array(self.df_grouped['u_in'].values.tolist())\n",
    "        self.u_outs = np.array(self.df_grouped['u_out'].values.tolist())\n",
    "        \n",
    "        cross = np.array(self.df_grouped['cross'].values.tolist())\n",
    "        cross2 = np.array(self.df_grouped['cross2'].values.tolist())\n",
    "        \n",
    "        area = np.array(self.df_grouped['area'].values.tolist())\n",
    "        time_step_cumsum = np.array(self.df_grouped['time_step_cumsum'].values.tolist())\n",
    "        u_in_cumsum = np.array(self.df_grouped['u_in_cumsum'].values.tolist())\n",
    "        \n",
    "        u_in_lag1 = np.array(self.df_grouped['u_in_lag1'].values.tolist())\n",
    "        u_out_lag1 = np.array(self.df_grouped['u_out_lag1'].values.tolist())\n",
    "        u_in_lag_back1 = np.array(self.df_grouped['u_in_lag_back1'].values.tolist())\n",
    "        u_out_lag_back1 = np.array(self.df_grouped['u_out_lag_back1'].values.tolist())\n",
    "        u_in_lag2 = np.array(self.df_grouped['u_in_lag2'].values.tolist())\n",
    "        u_out_lag2 = np.array(self.df_grouped['u_out_lag2'].values.tolist())\n",
    "        u_in_lag_back2 = np.array(self.df_grouped['u_in_lag_back2'].values.tolist())\n",
    "        u_out_lag_back2 = np.array(self.df_grouped['u_out_lag_back2'].values.tolist())\n",
    "        u_in_lag3 = np.array(self.df_grouped['u_in_lag3'].values.tolist())\n",
    "        u_out_lag3 = np.array(self.df_grouped['u_out_lag3'].values.tolist())\n",
    "        u_in_lag_back3 = np.array(self.df_grouped['u_in_lag_back3'].values.tolist())\n",
    "        u_out_lag_back3 = np.array(self.df_grouped['u_out_lag_back3'].values.tolist())\n",
    "        u_in_lag4 = np.array(self.df_grouped['u_in_lag4'].values.tolist())\n",
    "        u_out_lag4 = np.array(self.df_grouped['u_out_lag4'].values.tolist())\n",
    "        u_in_lag_back4 = np.array(self.df_grouped['u_in_lag_back4'].values.tolist())\n",
    "        u_out_lag_back4 = np.array(self.df_grouped['u_out_lag_back4'].values.tolist())\n",
    "        \n",
    "        breath_id__u_in__max = np.array(self.df_grouped['breath_id__u_in__max'].values.tolist())\n",
    "        breath_id__u_in__mean = np.array(self.df_grouped['breath_id__u_in__mean'].values.tolist())\n",
    "        breath_id__u_in__diffmax = np.array(self.df_grouped['breath_id__u_in__diffmax'].values.tolist())\n",
    "        breath_id__u_in__diffmean = np.array(self.df_grouped['breath_id__u_in__diffmean'].values.tolist())\n",
    "        \n",
    "        u_in_diff1 = np.array(self.df_grouped['u_in_diff1'].values.tolist())\n",
    "        u_out_diff1 = np.array(self.df_grouped['u_out_diff1'].values.tolist())\n",
    "        u_in_diff2 = np.array(self.df_grouped['u_in_diff2'].values.tolist())\n",
    "        u_out_diff2 = np.array(self.df_grouped['u_out_diff2'].values.tolist())\n",
    "        u_in_diff3 = np.array(self.df_grouped['u_in_diff3'].values.tolist())\n",
    "        u_out_diff3 = np.array(self.df_grouped['u_out_diff3'].values.tolist())\n",
    "        u_in_diff4 = np.array(self.df_grouped['u_in_diff4'].values.tolist())\n",
    "        u_out_diff4 = np.array(self.df_grouped['u_out_diff4'].values.tolist())\n",
    "        \n",
    "        count = np.array(self.df_grouped['count'].values.tolist())\n",
    "        u_in_cummean = np.array(self.df_grouped['u_in_cummean'].values.tolist())\n",
    "        \n",
    "        breath_id_lag = np.array(self.df_grouped['breath_id_lag'].values.tolist())\n",
    "        breath_id_lag2 = np.array(self.df_grouped['breath_id_lag2'].values.tolist())\n",
    "        breath_id_lagsame = np.array(self.df_grouped['breath_id_lagsame'].values.tolist())\n",
    "        breath_id_lag2same = np.array(self.df_grouped['breath_id_lag2same'].values.tolist())\n",
    "        breath_id__u_in_lag = np.array(self.df_grouped['breath_id__u_in_lag'].values.tolist())\n",
    "        breath_id__u_in_lag2 = np.array(self.df_grouped['breath_id__u_in_lag2'].values.tolist())\n",
    "        time_step_diff = np.array(self.df_grouped['time_step_diff'].values.tolist())\n",
    "        \n",
    "        v15_in_sum = np.array(self.df_grouped['15_in_sum'].values.tolist())\n",
    "        v15_in_min = np.array(self.df_grouped['15_in_min'].values.tolist())\n",
    "        v15_in_max = np.array(self.df_grouped['15_in_max'].values.tolist())\n",
    "        v15_in_mean = np.array(self.df_grouped['15_in_mean'].values.tolist())\n",
    "        \n",
    "        u_in_lagback_diff1 = np.array(self.df_grouped['u_in_lagback_diff1'].values.tolist())\n",
    "        u_out_lagback_diff1 = np.array(self.df_grouped['u_out_lagback_diff1'].values.tolist())\n",
    "        u_in_lagback_diff2 = np.array(self.df_grouped['u_in_lagback_diff2'].values.tolist())\n",
    "        u_out_lagback_diff2 = np.array(self.df_grouped['u_out_lagback_diff2'].values.tolist())\n",
    "        \n",
    "        R_20 = np.array(self.df_grouped['R_20'].values.tolist())\n",
    "        R_5 = np.array(self.df_grouped['R_5'].values.tolist())\n",
    "        R_50 = np.array(self.df_grouped['R_50'].values.tolist())\n",
    "        C_10 = np.array(self.df_grouped['C_10'].values.tolist())\n",
    "        C_20 = np.array(self.df_grouped['C_20'].values.tolist())\n",
    "        C_50 = np.array(self.df_grouped['C_50'].values.tolist())\n",
    "        R__C_20__10 = np.array(self.df_grouped['R__C_20__10'].values.tolist())\n",
    "        R__C_20__20 = np.array(self.df_grouped['R__C_20__20'].values.tolist())\n",
    "        R__C_20__50 = np.array(self.df_grouped['R__C_20__50'].values.tolist())\n",
    "        R__C_50__10 = np.array(self.df_grouped['R__C_50__10'].values.tolist())\n",
    "        R__C_50__20 = np.array(self.df_grouped['R__C_50__20'].values.tolist())\n",
    "        R__C_50__50 = np.array(self.df_grouped['R__C_50__50'].values.tolist())\n",
    "        R__C_5__10 = np.array(self.df_grouped['R__C_5__10'].values.tolist())\n",
    "        R__C_5__20 = np.array(self.df_grouped['R__C_5__20'].values.tolist())\n",
    "        R__C_5__50 = np.array(self.df_grouped['R__C_5__50'].values.tolist())\n",
    "        \n",
    "        \n",
    "        # [:, None] increases array dimension from 1 to 2, becomes a [[v1, v2, v3]] numpy array\n",
    "        self.inputs = np.concatenate([\n",
    "            u_ins[:, None], \n",
    "            self.u_outs[:, None],\n",
    "            \n",
    "            cross[:, None],\n",
    "            cross2[:, None],\n",
    "            \n",
    "            area[:, None],\n",
    "            time_step_cumsum[:, None],\n",
    "            u_in_cumsum[:, None],\n",
    "            \n",
    "            u_in_lag1[:, None],\n",
    "            u_out_lag1[:, None],\n",
    "            u_in_lag_back1[:, None],\n",
    "            u_out_lag_back1[:, None],\n",
    "            u_in_lag2[:, None],\n",
    "            u_out_lag2[:, None],\n",
    "            u_in_lag_back2[:, None],\n",
    "            u_out_lag_back2[:, None],\n",
    "            u_in_lag3[:, None],\n",
    "            u_out_lag3[:, None],\n",
    "            u_in_lag_back3[:, None],\n",
    "            u_out_lag_back3[:, None],\n",
    "            u_in_lag4[:, None],\n",
    "            u_out_lag4[:, None],\n",
    "            u_in_lag_back4[:, None],\n",
    "            u_out_lag_back4[:, None],\n",
    "            \n",
    "            breath_id__u_in__max[:, None],\n",
    "            breath_id__u_in__mean[:, None],\n",
    "            breath_id__u_in__diffmax[:, None],\n",
    "            breath_id__u_in__diffmean[:, None],\n",
    "            \n",
    "            u_in_diff1[:, None],\n",
    "            u_out_diff1[:, None],\n",
    "            u_in_diff2[:, None],\n",
    "            u_out_diff2[:, None],\n",
    "            u_in_diff3[:, None],\n",
    "            u_out_diff3[:, None],\n",
    "            u_in_diff4[:, None],\n",
    "            u_out_diff4[:, None],\n",
    "            \n",
    "            count[:, None],\n",
    "            u_in_cummean[:, None],\n",
    "            \n",
    "            breath_id_lag[:, None],\n",
    "            breath_id_lag2[:, None],\n",
    "            breath_id_lagsame[:, None],\n",
    "            breath_id_lag2same[:, None],\n",
    "            breath_id__u_in_lag[:, None],\n",
    "            breath_id__u_in_lag2[:, None],\n",
    "            time_step_diff[:, None],\n",
    "            \n",
    "            v15_in_sum[:, None],\n",
    "            v15_in_min[:, None],\n",
    "            v15_in_max[:, None],\n",
    "            v15_in_mean[:, None],\n",
    "            \n",
    "            u_in_lagback_diff1[:, None],\n",
    "            u_out_lagback_diff1[:, None],\n",
    "            u_in_lagback_diff2[:, None],\n",
    "            u_out_lagback_diff2[:, None],\n",
    "            \n",
    "            R_20[:, None],\n",
    "            R_5[:, None],\n",
    "            R_50[:, None],\n",
    "            C_10[:, None],\n",
    "            C_20[:, None],\n",
    "            C_50[:, None],\n",
    "            R__C_20__10[:, None],\n",
    "            R__C_20__20[:, None],\n",
    "            R__C_20__50[:, None],\n",
    "            R__C_50__10[:, None],\n",
    "            R__C_50__20[:, None],\n",
    "            R__C_50__50[:, None],\n",
    "            R__C_5__10[:, None],\n",
    "            R__C_5__20[:, None],\n",
    "            R__C_5__50[:, None],\n",
    "        ], axis = 1).transpose(0, 2, 1)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df_grouped.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        target = 'pressure'\n",
    "        return {\n",
    "            \"input\": torch.tensor(self.inputs[index], dtype=torch.float),\n",
    "            \"u_out\": torch.tensor(self.df_grouped.u_out[index], dtype=torch.int8),\n",
    "            \"p\": torch.tensor(self.df_grouped.loc[index, target], dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class wrapper from PyTorch nn.Module, so\n",
    "# the function now can be easily used in models\n",
    "\n",
    "# next time, fool, use directly the nn.SiLU() activation\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "    \n",
    "act_function = Swish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:52.834584Z",
     "iopub.status.busy": "2021-10-19T19:14:52.834138Z",
     "iopub.status.idle": "2021-10-19T19:14:52.846951Z",
     "shell.execute_reply": "2021-10-19T19:14:52.846099Z",
     "shell.execute_reply.started": "2021-10-19T19:14:52.83455Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM_archi(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        # nb of expected features\n",
    "        input_dim,\n",
    "        lstm_dim,\n",
    "        dense_dim,\n",
    "        logit_dim,\n",
    "        num_classes=1,\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.classic_layer = nn.Sequential(\n",
    "            nn.Linear(in_features = input_dim, out_features = 2*(dense_dim // 3)),\n",
    "            nn.ReLU(),\n",
    "            #act_function,\n",
    "        )\n",
    "        \n",
    "        self.upscale_layer = nn.Sequential(\n",
    "            nn.Linear(in_features =  2*(dense_dim // 3), out_features = dense_dim),\n",
    "            #act_function,\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.LSTM_layer = nn.LSTM(\n",
    "            input_size = dense_dim,\n",
    "            hidden_size = lstm_dim,\n",
    "            bidirectional = True,\n",
    "            num_layers = 4,\n",
    "            # then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature).\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(in_features = dense_dim * 2, out_features = logit_dim),\n",
    "            #act_function,\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(in_features = logit_dim, out_features = num_classes)\n",
    "        )\n",
    "        \n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.classic_layer(x)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.upscale_layer(x)\n",
    "        #x = self.dropout(x)\n",
    "        x, _ = self.LSTM_layer(x)\n",
    "        #x = self.dropout(x)\n",
    "        pred = self.output_layer(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:52.849031Z",
     "iopub.status.busy": "2021-10-19T19:14:52.848524Z",
     "iopub.status.idle": "2021-10-19T19:14:52.861808Z",
     "shell.execute_reply": "2021-10-19T19:14:52.861025Z",
     "shell.execute_reply.started": "2021-10-19T19:14:52.848992Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM_archi_3(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        # nb of expected features\n",
    "        input_dim,\n",
    "        lstm_dim,\n",
    "        dense_dim,\n",
    "        logit_dim,\n",
    "        num_classes=1,\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.classic_layer = nn.Sequential(\n",
    "            nn.Linear(in_features = input_dim, out_features = dense_dim),\n",
    "            act_function,\n",
    "        )\n",
    "        \n",
    "        self.LSTM_layer_1 = nn.LSTM(\n",
    "            input_size = dense_dim,\n",
    "            hidden_size = lstm_dim // 2,\n",
    "            bidirectional = True,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.LSTM_layer_2 = nn.LSTM(\n",
    "            input_size = lstm_dim,\n",
    "            hidden_size = lstm_dim // 4,\n",
    "            bidirectional = True,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.LSTM_layer_3 = nn.LSTM(\n",
    "            input_size = lstm_dim // 2,\n",
    "            hidden_size = lstm_dim // 8,\n",
    "            bidirectional = True,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.LSTM_layer_y = nn.LSTM(\n",
    "            input_size = lstm_dim // 2,\n",
    "            hidden_size = lstm_dim // 4,\n",
    "            bidirectional = True,\n",
    "            num_layers = 3,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.uplayer = nn.Sequential(\n",
    "            nn.Linear(in_features = input_dim, out_features = dense_dim),\n",
    "            act_function,\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(in_features = lstm_dim // 4, out_features = logit_dim),\n",
    "            nn.Linear(in_features = logit_dim, out_features = num_classes)\n",
    "        )\n",
    "        \n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.classic_layer(x)\n",
    "        y1 = self.classic_layer(x)\n",
    "        \n",
    "        x1, _ = self.LSTM_layer_1(x1)\n",
    "        x1, _ = self.LSTM_layer_2(x1)\n",
    "        x, _ = self.LSTM_layer_3(x)\n",
    "        \n",
    "        y1, _ = self.LSTM_layer_y(y1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred = self.output_layer(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_archi_2(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        # nb of expected features\n",
    "        input_dim,\n",
    "        lstm_dim,\n",
    "        dense_dim,\n",
    "        logit_dim,\n",
    "        num_classes=1,\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.classic_layer = nn.Sequential(\n",
    "            nn.Linear(in_features = input_dim, out_features = dense_dim),\n",
    "            act_function,\n",
    "        )\n",
    "        \n",
    "        self.LSTM_layer_1 = nn.LSTM(\n",
    "            input_size = dense_dim,\n",
    "            hidden_size = lstm_dim // 2,\n",
    "            bidirectional = True,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.LSTM_layer_2 = nn.LSTM(\n",
    "            input_size = lstm_dim,\n",
    "            hidden_size = lstm_dim // 4,\n",
    "            bidirectional = True,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.LSTM_layer_3 = nn.LSTM(\n",
    "            input_size = lstm_dim // 2,\n",
    "            hidden_size = lstm_dim // 8,\n",
    "            bidirectional = True,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(in_features = lstm_dim // 4, out_features = logit_dim),\n",
    "            nn.Linear(in_features = logit_dim, out_features = num_classes)\n",
    "        )\n",
    "        \n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.classic_layer(x)\n",
    "        x, _ = self.LSTM_layer_1(x)\n",
    "        #x = self.dropout(x)\n",
    "        x, _ = self.LSTM_layer_2(x)\n",
    "        #x = self.dropout(x)\n",
    "        x, _ = self.LSTM_layer_3(x)\n",
    "        #x = self.dropout(x)\n",
    "        pred = self.output_layer(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_archi(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim,\n",
    "        lstm_dim,\n",
    "        dense_dim,\n",
    "        logit_dim,\n",
    "        num_classes=1,\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.classic_layer = nn.Sequential(\n",
    "            nn.Linear(in_features = input_dim, out_features = dense_dim),\n",
    "            act_function,\n",
    "        )\n",
    "        \n",
    "        self.GRU_layer_1 = nn.GRU(\n",
    "            input_size = dense_dim,\n",
    "            hidden_size = lstm_dim // 2,\n",
    "            bidirectional = True,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.GRU_layer_2 = nn.GRU(\n",
    "            input_size = lstm_dim,\n",
    "            hidden_size = lstm_dim // 4,\n",
    "            bidirectional = True,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.GRU_layer_3 = nn.GRU(\n",
    "            input_size = lstm_dim // 2,\n",
    "            hidden_size = lstm_dim // 8,\n",
    "            bidirectional = True,\n",
    "            num_layers = 1,\n",
    "            batch_first = True,\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(in_features = lstm_dim // 4, out_features = logit_dim),\n",
    "            nn.Linear(in_features = logit_dim, out_features = num_classes)\n",
    "        )\n",
    "        \n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.classic_layer(x)\n",
    "        x, _ = self.GRU_layer_1(x)\n",
    "        x, _ = self.GRU_layer_2(x)\n",
    "        x, _ = self.GRU_layer_3(x)\n",
    "        pred = self.output_layer(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:52.864221Z",
     "iopub.status.busy": "2021-10-19T19:14:52.863217Z",
     "iopub.status.idle": "2021-10-19T19:14:52.874861Z",
     "shell.execute_reply": "2021-10-19T19:14:52.874013Z",
     "shell.execute_reply.started": "2021-10-19T19:14:52.864184Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Seeds basic parameters for reproductibility of results.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Number of the seed.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    \n",
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    Handles PyTorch x Numpy seeding issues.\n",
    "\n",
    "    Args:\n",
    "        worker_id (int): Id of the worker.\n",
    "    \"\"\"\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "    \n",
    "\n",
    "def save_model_weights(model, filename, verbose=1, cp_folder=\"\"):\n",
    "    \"\"\"\n",
    "    Saves the weights of a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model (torch model): Model to save the weights of.\n",
    "        filename (str): Name of the checkpoint.\n",
    "        verbose (int, optional): Whether to display infos. Defaults to 1.\n",
    "        cp_folder (str, optional): Folder to save to. Defaults to \"\".\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n -> Saving weights to {os.path.join(cp_folder, filename)}\\n\")\n",
    "    torch.save(model.state_dict(), os.path.join(cp_folder, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition will be scored as the mean absolute error between the predicted and actual pressures during the inspiratory phase of each breath. The expiratory phase is not scored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:52.876409Z",
     "iopub.status.busy": "2021-10-19T19:14:52.876075Z",
     "iopub.status.idle": "2021-10-19T19:14:52.887302Z",
     "shell.execute_reply": "2021-10-19T19:14:52.886489Z",
     "shell.execute_reply.started": "2021-10-19T19:14:52.876372Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metric(df, preds):\n",
    "    \"\"\"\n",
    "    Metric for the problem, as I understood it.\n",
    "    \"\"\"\n",
    "    \n",
    "    y = np.array(df['pressure'].values.tolist())\n",
    "\n",
    "    # inspiratory phase\n",
    "    mask = 1 - np.array(df['u_out'].values.tolist())\n",
    "        \n",
    "    # combine with mae calculusse\n",
    "    mae = mask * np.abs(y - preds)\n",
    "    mae = mae.sum() / mask.sum()\n",
    "    \n",
    "    return mae\n",
    "\n",
    "\n",
    "# Custom loss\n",
    "class VentilatorLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Directly optimizes the competition metric\n",
    "    \"\"\"\n",
    "    def __call__(self, preds, y, u_out):\n",
    "        mask = 1 - u_out\n",
    "        mae = mask * (y - preds).abs()\n",
    "        mae = mae.sum(-1) / mask.sum(-1)\n",
    "\n",
    "        return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:52.901789Z",
     "iopub.status.busy": "2021-10-19T19:14:52.900954Z",
     "iopub.status.idle": "2021-10-19T19:14:56.850291Z",
     "shell.execute_reply": "2021-10-19T19:14:56.849577Z",
     "shell.execute_reply.started": "2021-10-19T19:14:52.901754Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:56.852006Z",
     "iopub.status.busy": "2021-10-19T19:14:56.851751Z",
     "iopub.status.idle": "2021-10-19T19:14:56.870723Z",
     "shell.execute_reply": "2021-10-19T19:14:56.869742Z",
     "shell.execute_reply.started": "2021-10-19T19:14:56.851972Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    loss_name=\"L1Loss\",\n",
    "    optimizer=\"Adam\",\n",
    "    epochs=56,\n",
    "    batch_size=32,\n",
    "    val_bs=32,\n",
    "    warmup_prop=0.1,\n",
    "    lr=1e-3,\n",
    "    num_classes=1,\n",
    "    verbose=1,\n",
    "    first_epoch_eval=0,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    avg_val_loss = 0.\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = getattr(torch.optim, optimizer)(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        # how many samples per batch to load\n",
    "        batch_size=batch_size,\n",
    "        # to have the data reshuffled at every epoch\n",
    "        shuffle=True,\n",
    "        # drop the last incomplete batch\n",
    "        drop_last=True,\n",
    "        num_workers=4,\n",
    "        # the data loader will copy Tensors into CUDA pinned memory before returning them.\n",
    "        pin_memory=True,\n",
    "        # this will be called on each worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as input, after seeding and before data loading.\n",
    "        #worker_init_fn=worker_init_fn\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=val_bs,\n",
    "        # no shuffling val data at every epochs meaning validating on same batches of data\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # Loss\n",
    "    loss_fct = VentilatorLoss()\n",
    "\n",
    "    # Scheduler\n",
    "    num_warmup_steps = int(warmup_prop * epochs * len(train_loader))\n",
    "    num_training_steps = int(epochs * len(train_loader))\n",
    "    # Create a schedule with a varying learning rate\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps, \n",
    "        num_training_steps\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # Sets the gradients of all optimized Tensors to zero.\n",
    "        model.zero_grad()\n",
    "        start_time = time.time()\n",
    "\n",
    "        avg_loss = 0\n",
    "\n",
    "        for data in train_loader:\n",
    "            \n",
    "            \n",
    "            pred = model(data['input'].to(device)).squeeze(-1)\n",
    "\n",
    "            loss = loss_fct(\n",
    "                pred,\n",
    "                data['p'].to(device),\n",
    "                data['u_out'].to(device),\n",
    "            ).mean()\n",
    "            # Computes the gradient of current tensor w.r.t. (with respect to) graph leaves.\n",
    "            loss.backward()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "\n",
    "        model.eval()\n",
    "        mae, avg_val_loss = 0, 0\n",
    "        preds = []\n",
    "\n",
    "        # Context-manager that disable gradient calculation. To use when dealing with validation datasets\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                pred = model(data['input'].to(device)).squeeze(-1)\n",
    "\n",
    "                loss = loss_fct(\n",
    "                    pred.detach(), \n",
    "                    data['p'].to(device),\n",
    "                    data['u_out'].to(device),\n",
    "                ).mean()\n",
    "                avg_val_loss += loss.item() / len(val_loader)\n",
    "\n",
    "                preds.append(pred.detach().cpu().numpy())\n",
    "        \n",
    "        preds = np.concatenate(preds, 0)\n",
    "        mae = compute_metric(val_dataset.df_grouped, preds)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if (epoch + 1) % verbose == 0:\n",
    "            elapsed_time = elapsed_time * verbose\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1:02d}/{epochs:02d} \\t lr={lr:.1e}\\t t={elapsed_time:.0f}s \\t\"\n",
    "                f\"loss={avg_loss:.3f}\",\n",
    "                end=\"\\t\",\n",
    "            )\n",
    "\n",
    "            if (epoch + 1 >= first_epoch_eval) or (epoch + 1 == epochs):\n",
    "                print(f\"val_loss={avg_val_loss:.3f}\\tmae={mae:.3f}\")\n",
    "            else:\n",
    "                print(\"\")\n",
    "\n",
    "    del (val_loader, train_loader, loss, data, pred)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:56.872583Z",
     "iopub.status.busy": "2021-10-19T19:14:56.872195Z",
     "iopub.status.idle": "2021-10-19T19:14:56.886134Z",
     "shell.execute_reply": "2021-10-19T19:14:56.885396Z",
     "shell.execute_reply.started": "2021-10-19T19:14:56.872525Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model,\n",
    "    dataset,\n",
    "    batch_size = 64,\n",
    "    device = \"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (torch model): Model to predict with.\n",
    "        dataset (PathologyDataset): Dataset to predict on.\n",
    "        batch_size (int, optional): Batch size. Defaults to 64.\n",
    "        device (str, optional): Device for torch. Defaults to \"cuda\".\n",
    "\n",
    "    Returns:\n",
    "        numpy array [len(dataset) x num_classes] preds.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size = batch_size, \n",
    "        shuffle = False, \n",
    "        num_workers = 4\n",
    "    )\n",
    "    \n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            pred = model(data['input'].to(device)).squeeze(-1)\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds, axis = 0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:56.888483Z",
     "iopub.status.busy": "2021-10-19T19:14:56.887681Z",
     "iopub.status.idle": "2021-10-19T19:14:56.904422Z",
     "shell.execute_reply": "2021-10-19T19:14:56.903487Z",
     "shell.execute_reply.started": "2021-10-19T19:14:56.888444Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(config, df_train, df_val, df_test, fold):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        config (Config): Parameters.\n",
    "        df_train (pandas dataframe): Training metadata.\n",
    "        df_val (pandas dataframe): Validation metadata.\n",
    "        df_test (pandas dataframe): Test metadata.\n",
    "        fold (int): Selected fold.\n",
    "\n",
    "    Returns:\n",
    "        np array: Study validation predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Seed\n",
    "    seed_everything(config.seed)\n",
    "\n",
    "    # Load model arch\n",
    "    model = LSTM_archi_2(\n",
    "        input_dim = config.input_dim,\n",
    "        lstm_dim = config.lstm_dim,\n",
    "        dense_dim = config.dense_dim,\n",
    "        logit_dim = config.logit_dim,\n",
    "        num_classes = config.num_classes,\n",
    "    ).to(config.device)\n",
    "    model.zero_grad()\n",
    "\n",
    "    train_dataset = VPPDataLoader(df_train)\n",
    "    val_dataset = VPPDataLoader(df_val)\n",
    "    test_dataset = VPPDataLoader(df_test)\n",
    "\n",
    "    print(f\"    -> {len(train_dataset)} training breathes\")\n",
    "    print(f\"    -> {len(val_dataset)} validation breathes\")\n",
    "\n",
    "    pred_val = fit(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        loss_name = config.loss,\n",
    "        optimizer = config.optimizer,\n",
    "        epochs = config.epochs,\n",
    "        batch_size = config.batch_size,\n",
    "        val_bs = config.val_bs,\n",
    "        lr = config.lr,\n",
    "        warmup_prop = config.warmup_prop,\n",
    "        verbose = config.verbose,\n",
    "        first_epoch_eval = config.first_epoch_eval,\n",
    "        device = config.device,\n",
    "    )\n",
    "    \n",
    "    pred_test = predict(\n",
    "        model, \n",
    "        test_dataset, \n",
    "        batch_size = config.val_bs, \n",
    "        device = config.device\n",
    "    )\n",
    "\n",
    "    if config.save_weights:\n",
    "        save_model_weights(\n",
    "            model,\n",
    "            f\"{config.selected_model}_{fold}.pt\",\n",
    "            cp_folder = \"\",\n",
    "        )\n",
    "\n",
    "    del (model, train_dataset, val_dataset, test_dataset)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return pred_val, pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:56.907959Z",
     "iopub.status.busy": "2021-10-19T19:14:56.907749Z",
     "iopub.status.idle": "2021-10-19T19:14:56.918193Z",
     "shell.execute_reply": "2021-10-19T19:14:56.917402Z",
     "shell.execute_reply.started": "2021-10-19T19:14:56.907936Z"
    }
   },
   "outputs": [],
   "source": [
    "def k_fold(config, df, df_test):\n",
    "    \"\"\"\n",
    "    Performs a patient grouped k-fold cross validation.\n",
    "    \"\"\"\n",
    "\n",
    "    pred_oof = np.zeros(len(df))\n",
    "    preds_test = []\n",
    "    \n",
    "    gkf = GroupKFold(n_splits = config.k)\n",
    "    splits = list(gkf.split(X = df, y = df, groups = df[\"breath_id\"]))\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(splits):\n",
    "        if i in config.selected_folds:\n",
    "            print(f\"\\n-------------   Fold {i + 1} / {config.k}  -------------\\n\")\n",
    "\n",
    "            df_train = df.iloc[train_idx].copy().reset_index(drop = True)\n",
    "            df_val = df.iloc[val_idx].copy().reset_index(drop = True)\n",
    "\n",
    "            pred_val, pred_test = train(config, df_train, df_val, df_test, i)\n",
    "            \n",
    "            pred_oof[val_idx] = pred_val.flatten()\n",
    "            preds_test.append(pred_test.flatten())\n",
    "\n",
    "    print(f'\\n -> CV MAE : {compute_metric(df, pred_oof) :.3f}')\n",
    "\n",
    "    return pred_oof, np.mean(preds_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:56.921826Z",
     "iopub.status.busy": "2021-10-19T19:14:56.920704Z",
     "iopub.status.idle": "2021-10-19T19:14:56.973907Z",
     "shell.execute_reply": "2021-10-19T19:14:56.973077Z",
     "shell.execute_reply.started": "2021-10-19T19:14:56.921796Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    save_weights = True\n",
    "\n",
    "    # k-fold\n",
    "    k = 7\n",
    "    selected_folds = [0, 1, 2, 3, 4, 5, 6]\n",
    "    \n",
    "    # Model\n",
    "    selected_model = 'LSTM'\n",
    "    input_dim = 67 \n",
    "\n",
    "    dense_dim = 512\n",
    "    lstm_dim = 512\n",
    "    logit_dim = 512\n",
    "    num_classes = 1\n",
    "\n",
    "    # Training\n",
    "    loss = \"L1Loss\"  # not used\n",
    "    optimizer = \"Adam\"\n",
    "    batch_size = 256\n",
    "    epochs = 100\n",
    "\n",
    "    lr = 1e-3\n",
    "    warmup_prop = 0\n",
    "\n",
    "    val_bs = 256\n",
    "    first_epoch_eval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T19:14:56.978644Z",
     "iopub.status.busy": "2021-10-19T19:14:56.977213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------   Fold 1 / 7  -------------\n",
      "\n",
      "    -> 64671 training breathes\n",
      "    -> 10779 validation breathes\n",
      "Epoch 01/100 \t lr=9.9e-04\t t=22s \tloss=3.375\tval_loss=1.465\tmae=1.475\n",
      "Epoch 02/100 \t lr=9.8e-04\t t=22s \tloss=1.288\tval_loss=1.048\tmae=1.051\n",
      "Epoch 03/100 \t lr=9.7e-04\t t=22s \tloss=1.069\tval_loss=0.891\tmae=0.894\n",
      "Epoch 04/100 \t lr=9.6e-04\t t=22s \tloss=0.851\tval_loss=1.372\tmae=1.373\n",
      "Epoch 05/100 \t lr=9.5e-04\t t=22s \tloss=0.853\tval_loss=0.749\tmae=0.750\n",
      "Epoch 06/100 \t lr=9.4e-04\t t=22s \tloss=0.748\tval_loss=0.776\tmae=0.777\n",
      "Epoch 07/100 \t lr=9.3e-04\t t=22s \tloss=0.692\tval_loss=0.715\tmae=0.717\n",
      "Epoch 08/100 \t lr=9.2e-04\t t=22s \tloss=0.675\tval_loss=0.830\tmae=0.832\n",
      "Epoch 09/100 \t lr=9.1e-04\t t=22s \tloss=0.644\tval_loss=0.666\tmae=0.670\n",
      "Epoch 10/100 \t lr=9.0e-04\t t=22s \tloss=0.609\tval_loss=0.595\tmae=0.595\n",
      "Epoch 11/100 \t lr=8.9e-04\t t=22s \tloss=0.610\tval_loss=0.623\tmae=0.625\n",
      "Epoch 12/100 \t lr=8.8e-04\t t=22s \tloss=0.566\tval_loss=0.664\tmae=0.666\n",
      "Epoch 13/100 \t lr=8.7e-04\t t=22s \tloss=0.555\tval_loss=0.566\tmae=0.565\n",
      "Epoch 14/100 \t lr=8.6e-04\t t=22s \tloss=0.549\tval_loss=0.553\tmae=0.554\n",
      "Epoch 15/100 \t lr=8.5e-04\t t=22s \tloss=0.539\tval_loss=0.580\tmae=0.583\n",
      "Epoch 16/100 \t lr=8.4e-04\t t=22s \tloss=0.547\tval_loss=0.505\tmae=0.506\n",
      "Epoch 17/100 \t lr=8.3e-04\t t=22s \tloss=0.499\tval_loss=0.510\tmae=0.512\n",
      "Epoch 18/100 \t lr=8.2e-04\t t=22s \tloss=0.481\tval_loss=0.500\tmae=0.501\n",
      "Epoch 19/100 \t lr=8.1e-04\t t=22s \tloss=0.484\tval_loss=0.507\tmae=0.510\n",
      "Epoch 20/100 \t lr=8.0e-04\t t=22s \tloss=0.475\tval_loss=0.465\tmae=0.467\n",
      "Epoch 21/100 \t lr=7.9e-04\t t=22s \tloss=0.464\tval_loss=0.476\tmae=0.477\n",
      "Epoch 22/100 \t lr=7.8e-04\t t=22s \tloss=0.446\tval_loss=0.448\tmae=0.450\n",
      "Epoch 23/100 \t lr=7.7e-04\t t=22s \tloss=0.451\tval_loss=0.437\tmae=0.439\n",
      "Epoch 24/100 \t lr=7.6e-04\t t=22s \tloss=0.438\tval_loss=0.461\tmae=0.464\n",
      "Epoch 25/100 \t lr=7.5e-04\t t=22s \tloss=0.450\tval_loss=0.435\tmae=0.437\n",
      "Epoch 26/100 \t lr=7.4e-04\t t=22s \tloss=0.432\tval_loss=0.462\tmae=0.465\n",
      "Epoch 27/100 \t lr=7.3e-04\t t=22s \tloss=0.428\tval_loss=0.429\tmae=0.432\n",
      "Epoch 28/100 \t lr=7.2e-04\t t=22s \tloss=0.413\tval_loss=0.428\tmae=0.430\n",
      "Epoch 29/100 \t lr=7.1e-04\t t=22s \tloss=0.424\tval_loss=0.561\tmae=0.561\n",
      "Epoch 30/100 \t lr=7.0e-04\t t=22s \tloss=0.431\tval_loss=0.434\tmae=0.438\n",
      "Epoch 31/100 \t lr=6.9e-04\t t=22s \tloss=0.387\tval_loss=0.431\tmae=0.431\n",
      "Epoch 32/100 \t lr=6.8e-04\t t=22s \tloss=0.388\tval_loss=0.399\tmae=0.401\n",
      "Epoch 33/100 \t lr=6.7e-04\t t=22s \tloss=0.391\tval_loss=0.464\tmae=0.468\n",
      "Epoch 34/100 \t lr=6.6e-04\t t=22s \tloss=0.398\tval_loss=0.437\tmae=0.438\n",
      "Epoch 35/100 \t lr=6.5e-04\t t=22s \tloss=0.403\tval_loss=0.394\tmae=0.395\n",
      "Epoch 36/100 \t lr=6.4e-04\t t=22s \tloss=0.415\tval_loss=0.401\tmae=0.402\n",
      "Epoch 37/100 \t lr=6.3e-04\t t=22s \tloss=0.373\tval_loss=0.452\tmae=0.454\n",
      "Epoch 38/100 \t lr=6.2e-04\t t=22s \tloss=0.390\tval_loss=0.403\tmae=0.407\n",
      "Epoch 39/100 \t lr=6.1e-04\t t=22s \tloss=0.377\tval_loss=0.474\tmae=0.472\n",
      "Epoch 40/100 \t lr=6.0e-04\t t=22s \tloss=0.399\tval_loss=0.417\tmae=0.419\n",
      "Epoch 41/100 \t lr=5.9e-04\t t=22s \tloss=0.390\tval_loss=0.435\tmae=0.437\n",
      "Epoch 42/100 \t lr=5.8e-04\t t=22s \tloss=0.364\tval_loss=0.412\tmae=0.415\n",
      "Epoch 43/100 \t lr=5.7e-04\t t=22s \tloss=0.358\tval_loss=0.357\tmae=0.358\n",
      "Epoch 44/100 \t lr=5.6e-04\t t=22s \tloss=0.363\tval_loss=0.414\tmae=0.417\n",
      "Epoch 45/100 \t lr=5.5e-04\t t=22s \tloss=0.391\tval_loss=0.366\tmae=0.368\n",
      "Epoch 46/100 \t lr=5.4e-04\t t=22s \tloss=0.337\tval_loss=0.375\tmae=0.376\n",
      "Epoch 47/100 \t lr=5.3e-04\t t=22s \tloss=0.341\tval_loss=0.386\tmae=0.388\n",
      "Epoch 48/100 \t lr=5.2e-04\t t=22s \tloss=0.333\tval_loss=0.343\tmae=0.346\n",
      "Epoch 49/100 \t lr=5.1e-04\t t=22s \tloss=0.325\tval_loss=0.339\tmae=0.342\n",
      "Epoch 50/100 \t lr=5.0e-04\t t=22s \tloss=0.308\tval_loss=0.331\tmae=0.334\n",
      "Epoch 51/100 \t lr=4.9e-04\t t=22s \tloss=0.327\tval_loss=0.349\tmae=0.351\n",
      "Epoch 52/100 \t lr=4.8e-04\t t=22s \tloss=0.357\tval_loss=0.358\tmae=0.359\n",
      "Epoch 53/100 \t lr=4.7e-04\t t=22s \tloss=0.316\tval_loss=0.365\tmae=0.368\n",
      "Epoch 54/100 \t lr=4.6e-04\t t=22s \tloss=0.319\tval_loss=0.348\tmae=0.351\n",
      "Epoch 55/100 \t lr=4.5e-04\t t=22s \tloss=0.302\tval_loss=0.344\tmae=0.346\n",
      "Epoch 56/100 \t lr=4.4e-04\t t=22s \tloss=0.297\tval_loss=0.350\tmae=0.352\n",
      "Epoch 57/100 \t lr=4.3e-04\t t=22s \tloss=0.289\tval_loss=0.340\tmae=0.342\n",
      "Epoch 58/100 \t lr=4.2e-04\t t=22s \tloss=0.288\tval_loss=0.305\tmae=0.308\n",
      "Epoch 59/100 \t lr=4.1e-04\t t=22s \tloss=0.284\tval_loss=0.319\tmae=0.322\n",
      "Epoch 60/100 \t lr=4.0e-04\t t=22s \tloss=0.284\tval_loss=0.405\tmae=0.405\n",
      "Epoch 61/100 \t lr=3.9e-04\t t=22s \tloss=0.347\tval_loss=0.324\tmae=0.327\n",
      "Epoch 62/100 \t lr=3.8e-04\t t=22s \tloss=0.340\tval_loss=0.347\tmae=0.350\n",
      "Epoch 63/100 \t lr=3.7e-04\t t=22s \tloss=0.279\tval_loss=0.305\tmae=0.308\n",
      "Epoch 64/100 \t lr=3.6e-04\t t=22s \tloss=0.289\tval_loss=0.332\tmae=0.334\n",
      "Epoch 65/100 \t lr=3.5e-04\t t=22s \tloss=0.285\tval_loss=0.466\tmae=0.470\n",
      "Epoch 66/100 \t lr=3.4e-04\t t=22s \tloss=0.292\tval_loss=0.303\tmae=0.305\n",
      "Epoch 67/100 \t lr=3.3e-04\t t=22s \tloss=0.267\tval_loss=0.313\tmae=0.316\n",
      "Epoch 68/100 \t lr=3.2e-04\t t=22s \tloss=0.279\tval_loss=0.311\tmae=0.314\n",
      "Epoch 69/100 \t lr=3.1e-04\t t=22s \tloss=0.253\tval_loss=0.289\tmae=0.292\n",
      "Epoch 70/100 \t lr=3.0e-04\t t=22s \tloss=0.241\tval_loss=0.284\tmae=0.287\n",
      "Epoch 71/100 \t lr=2.9e-04\t t=22s \tloss=0.241\tval_loss=0.288\tmae=0.290\n",
      "Epoch 72/100 \t lr=2.8e-04\t t=22s \tloss=0.238\tval_loss=0.280\tmae=0.283\n",
      "Epoch 73/100 \t lr=2.7e-04\t t=22s \tloss=0.242\tval_loss=0.277\tmae=0.279\n",
      "Epoch 74/100 \t lr=2.6e-04\t t=22s \tloss=0.235\tval_loss=0.285\tmae=0.288\n",
      "Epoch 75/100 \t lr=2.5e-04\t t=22s \tloss=0.242\tval_loss=0.278\tmae=0.280\n",
      "Epoch 76/100 \t lr=2.4e-04\t t=22s \tloss=0.227\tval_loss=0.282\tmae=0.284\n",
      "Epoch 77/100 \t lr=2.3e-04\t t=22s \tloss=0.222\tval_loss=0.273\tmae=0.275\n",
      "Epoch 78/100 \t lr=2.2e-04\t t=22s \tloss=0.220\tval_loss=0.273\tmae=0.276\n",
      "Epoch 79/100 \t lr=2.1e-04\t t=22s \tloss=0.217\tval_loss=0.264\tmae=0.266\n",
      "Epoch 80/100 \t lr=2.0e-04\t t=22s \tloss=0.213\tval_loss=0.263\tmae=0.265\n",
      "Epoch 81/100 \t lr=1.9e-04\t t=22s \tloss=0.262\tval_loss=0.276\tmae=0.278\n",
      "Epoch 82/100 \t lr=1.8e-04\t t=22s \tloss=0.220\tval_loss=0.271\tmae=0.273\n",
      "Epoch 83/100 \t lr=1.7e-04\t t=22s \tloss=0.215\tval_loss=0.260\tmae=0.262\n",
      "Epoch 84/100 \t lr=1.6e-04\t t=22s \tloss=0.214\tval_loss=0.261\tmae=0.263\n",
      "Epoch 85/100 \t lr=1.5e-04\t t=22s \tloss=0.209\tval_loss=0.261\tmae=0.263\n",
      "Epoch 86/100 \t lr=1.4e-04\t t=22s \tloss=0.204\tval_loss=0.259\tmae=0.261\n",
      "Epoch 87/100 \t lr=1.3e-04\t t=22s \tloss=0.200\tval_loss=0.255\tmae=0.257\n",
      "Epoch 88/100 \t lr=1.2e-04\t t=22s \tloss=0.200\tval_loss=0.255\tmae=0.256\n",
      "Epoch 89/100 \t lr=1.1e-04\t t=22s \tloss=0.197\tval_loss=0.254\tmae=0.256\n",
      "Epoch 90/100 \t lr=1.0e-04\t t=22s \tloss=0.195\tval_loss=0.252\tmae=0.254\n",
      "Epoch 91/100 \t lr=9.0e-05\t t=22s \tloss=0.193\tval_loss=0.254\tmae=0.256\n",
      "Epoch 92/100 \t lr=8.0e-05\t t=22s \tloss=0.192\tval_loss=0.252\tmae=0.254\n",
      "Epoch 93/100 \t lr=7.0e-05\t t=22s \tloss=0.190\tval_loss=0.251\tmae=0.253\n",
      "Epoch 94/100 \t lr=6.0e-05\t t=22s \tloss=0.188\tval_loss=0.249\tmae=0.251\n",
      "Epoch 95/100 \t lr=5.0e-05\t t=22s \tloss=0.186\tval_loss=0.250\tmae=0.252\n",
      "Epoch 96/100 \t lr=4.0e-05\t t=22s \tloss=0.185\tval_loss=0.248\tmae=0.250\n",
      "Epoch 97/100 \t lr=3.0e-05\t t=22s \tloss=0.184\tval_loss=0.248\tmae=0.250\n",
      "Epoch 98/100 \t lr=2.0e-05\t t=22s \tloss=0.182\tval_loss=0.247\tmae=0.249\n",
      "Epoch 100/100 \t lr=0.0e+00\t t=22s \tloss=0.180\tval_loss=0.246\tmae=0.248\n",
      "\n",
      " -> Saving weights to LSTM_0.pt\n",
      "\n",
      "\n",
      "-------------   Fold 2 / 7  -------------\n",
      "\n",
      "    -> 64671 training breathes\n",
      "    -> 10779 validation breathes\n",
      "Epoch 01/100 \t lr=9.9e-04\t t=22s \tloss=3.310\tval_loss=1.453\tmae=1.458\n",
      "Epoch 02/100 \t lr=9.8e-04\t t=22s \tloss=1.232\tval_loss=0.962\tmae=0.966\n",
      "Epoch 03/100 \t lr=9.7e-04\t t=22s \tloss=0.993\tval_loss=0.894\tmae=0.894\n",
      "Epoch 04/100 \t lr=9.6e-04\t t=22s \tloss=0.859\tval_loss=1.135\tmae=1.136\n",
      "Epoch 05/100 \t lr=9.5e-04\t t=22s \tloss=0.807\tval_loss=0.753\tmae=0.753\n",
      "Epoch 06/100 \t lr=9.4e-04\t t=22s \tloss=0.748\tval_loss=0.860\tmae=0.862\n",
      "Epoch 07/100 \t lr=9.3e-04\t t=22s \tloss=0.759\tval_loss=0.673\tmae=0.674\n",
      "Epoch 08/100 \t lr=9.2e-04\t t=22s \tloss=0.663\tval_loss=0.707\tmae=0.710\n",
      "Epoch 09/100 \t lr=9.1e-04\t t=22s \tloss=0.647\tval_loss=0.632\tmae=0.634\n",
      "Epoch 10/100 \t lr=9.0e-04\t t=22s \tloss=0.632\tval_loss=0.626\tmae=0.628\n",
      "Epoch 11/100 \t lr=8.9e-04\t t=22s \tloss=0.607\tval_loss=0.620\tmae=0.623\n",
      "Epoch 12/100 \t lr=8.8e-04\t t=22s \tloss=0.575\tval_loss=0.704\tmae=0.707\n",
      "Epoch 13/100 \t lr=8.7e-04\t t=22s \tloss=0.578\tval_loss=0.598\tmae=0.600\n",
      "Epoch 14/100 \t lr=8.6e-04\t t=22s \tloss=0.579\tval_loss=0.543\tmae=0.545\n",
      "Epoch 15/100 \t lr=8.5e-04\t t=22s \tloss=0.540\tval_loss=0.533\tmae=0.534\n",
      "Epoch 16/100 \t lr=8.4e-04\t t=22s \tloss=0.537\tval_loss=0.532\tmae=0.534\n",
      "Epoch 17/100 \t lr=8.3e-04\t t=22s \tloss=0.511\tval_loss=0.521\tmae=0.524\n",
      "Epoch 18/100 \t lr=8.2e-04\t t=22s \tloss=0.502\tval_loss=0.511\tmae=0.514\n",
      "Epoch 19/100 \t lr=8.1e-04\t t=22s \tloss=0.501\tval_loss=0.703\tmae=0.703\n",
      "Epoch 20/100 \t lr=8.0e-04\t t=22s \tloss=0.508\tval_loss=0.485\tmae=0.488\n",
      "Epoch 21/100 \t lr=7.9e-04\t t=22s \tloss=0.480\tval_loss=0.481\tmae=0.484\n",
      "Epoch 22/100 \t lr=7.8e-04\t t=22s \tloss=0.470\tval_loss=0.486\tmae=0.489\n",
      "Epoch 23/100 \t lr=7.7e-04\t t=22s \tloss=0.465\tval_loss=0.518\tmae=0.521\n",
      "Epoch 24/100 \t lr=7.6e-04\t t=22s \tloss=0.455\tval_loss=0.462\tmae=0.465\n",
      "Epoch 25/100 \t lr=7.5e-04\t t=22s \tloss=0.454\tval_loss=0.492\tmae=0.495\n",
      "Epoch 26/100 \t lr=7.4e-04\t t=22s \tloss=0.442\tval_loss=0.472\tmae=0.473\n",
      "Epoch 27/100 \t lr=7.3e-04\t t=22s \tloss=0.430\tval_loss=0.475\tmae=0.478\n",
      "Epoch 28/100 \t lr=7.2e-04\t t=22s \tloss=0.428\tval_loss=0.445\tmae=0.446\n",
      "Epoch 29/100 \t lr=7.1e-04\t t=22s \tloss=0.422\tval_loss=0.435\tmae=0.438\n",
      "Epoch 30/100 \t lr=7.0e-04\t t=22s \tloss=0.418\tval_loss=0.435\tmae=0.436\n",
      "Epoch 31/100 \t lr=6.9e-04\t t=22s \tloss=0.411\tval_loss=0.418\tmae=0.419\n",
      "Epoch 32/100 \t lr=6.8e-04\t t=22s \tloss=0.403\tval_loss=0.418\tmae=0.420\n",
      "Epoch 33/100 \t lr=6.7e-04\t t=22s \tloss=0.387\tval_loss=0.416\tmae=0.417\n",
      "Epoch 34/100 \t lr=6.6e-04\t t=22s \tloss=0.387\tval_loss=0.422\tmae=0.425\n",
      "Epoch 35/100 \t lr=6.5e-04\t t=22s \tloss=0.388\tval_loss=0.422\tmae=0.424\n",
      "Epoch 36/100 \t lr=6.4e-04\t t=22s \tloss=0.382\tval_loss=0.396\tmae=0.398\n",
      "Epoch 37/100 \t lr=6.3e-04\t t=22s \tloss=0.366\tval_loss=0.400\tmae=0.402\n",
      "Epoch 38/100 \t lr=6.2e-04\t t=22s \tloss=0.357\tval_loss=0.390\tmae=0.392\n",
      "Epoch 39/100 \t lr=6.1e-04\t t=22s \tloss=0.351\tval_loss=0.381\tmae=0.384\n",
      "Epoch 40/100 \t lr=6.0e-04\t t=22s \tloss=0.353\tval_loss=0.374\tmae=0.376\n",
      "Epoch 41/100 \t lr=5.9e-04\t t=22s \tloss=0.353\tval_loss=0.380\tmae=0.382\n",
      "Epoch 42/100 \t lr=5.8e-04\t t=22s \tloss=0.340\tval_loss=0.504\tmae=0.507\n",
      "Epoch 43/100 \t lr=5.7e-04\t t=22s \tloss=0.346\tval_loss=0.367\tmae=0.369\n",
      "Epoch 44/100 \t lr=5.6e-04\t t=22s \tloss=0.352\tval_loss=0.361\tmae=0.363\n",
      "Epoch 45/100 \t lr=5.5e-04\t t=22s \tloss=0.332\tval_loss=0.362\tmae=0.364\n",
      "Epoch 46/100 \t lr=5.4e-04\t t=22s \tloss=0.326\tval_loss=0.346\tmae=0.345\n",
      "Epoch 47/100 \t lr=5.3e-04\t t=22s \tloss=0.328\tval_loss=0.352\tmae=0.354\n",
      "Epoch 48/100 \t lr=5.2e-04\t t=22s \tloss=0.318\tval_loss=0.373\tmae=0.375\n",
      "Epoch 49/100 \t lr=5.1e-04\t t=22s \tloss=0.320\tval_loss=0.360\tmae=0.362\n",
      "Epoch 50/100 \t lr=5.0e-04\t t=22s \tloss=0.312\tval_loss=0.341\tmae=0.343\n",
      "Epoch 51/100 \t lr=4.9e-04\t t=22s \tloss=0.288\tval_loss=0.329\tmae=0.331\n",
      "Epoch 52/100 \t lr=4.8e-04\t t=22s \tloss=0.297\tval_loss=0.349\tmae=0.350\n",
      "Epoch 53/100 \t lr=4.7e-04\t t=22s \tloss=0.304\tval_loss=0.322\tmae=0.323\n",
      "Epoch 54/100 \t lr=4.6e-04\t t=22s \tloss=0.292\tval_loss=0.338\tmae=0.341\n",
      "Epoch 55/100 \t lr=4.5e-04\t t=22s \tloss=0.289\tval_loss=0.330\tmae=0.332\n",
      "Epoch 56/100 \t lr=4.4e-04\t t=22s \tloss=0.273\tval_loss=0.317\tmae=0.318\n",
      "Epoch 57/100 \t lr=4.3e-04\t t=22s \tloss=0.282\tval_loss=0.409\tmae=0.408\n",
      "Epoch 58/100 \t lr=4.2e-04\t t=22s \tloss=0.292\tval_loss=0.380\tmae=0.382\n",
      "Epoch 59/100 \t lr=4.1e-04\t t=22s \tloss=0.294\tval_loss=0.379\tmae=0.383\n",
      "Epoch 60/100 \t lr=4.0e-04\t t=22s \tloss=0.286\tval_loss=0.312\tmae=0.314\n",
      "Epoch 61/100 \t lr=3.9e-04\t t=22s \tloss=0.255\tval_loss=0.309\tmae=0.311\n",
      "Epoch 62/100 \t lr=3.8e-04\t t=22s \tloss=0.302\tval_loss=0.332\tmae=0.335\n",
      "Epoch 63/100 \t lr=3.7e-04\t t=22s \tloss=0.266\tval_loss=0.314\tmae=0.315\n",
      "Epoch 64/100 \t lr=3.6e-04\t t=22s \tloss=0.251\tval_loss=0.294\tmae=0.296\n",
      "Epoch 65/100 \t lr=3.5e-04\t t=22s \tloss=0.253\tval_loss=0.308\tmae=0.309\n",
      "Epoch 66/100 \t lr=3.4e-04\t t=22s \tloss=0.252\tval_loss=0.303\tmae=0.305\n",
      "Epoch 67/100 \t lr=3.3e-04\t t=22s \tloss=0.254\tval_loss=0.288\tmae=0.289\n",
      "Epoch 68/100 \t lr=3.2e-04\t t=22s \tloss=0.237\tval_loss=0.288\tmae=0.289\n",
      "Epoch 69/100 \t lr=3.1e-04\t t=22s \tloss=0.231\tval_loss=0.285\tmae=0.287\n",
      "Epoch 70/100 \t lr=3.0e-04\t t=22s \tloss=0.233\tval_loss=0.288\tmae=0.289\n",
      "Epoch 71/100 \t lr=2.9e-04\t t=22s \tloss=0.226\tval_loss=0.284\tmae=0.287\n",
      "Epoch 72/100 \t lr=2.8e-04\t t=22s \tloss=0.231\tval_loss=0.280\tmae=0.282\n",
      "Epoch 73/100 \t lr=2.7e-04\t t=22s \tloss=0.256\tval_loss=0.288\tmae=0.290\n",
      "Epoch 74/100 \t lr=2.6e-04\t t=22s \tloss=0.226\tval_loss=0.281\tmae=0.283\n",
      "Epoch 75/100 \t lr=2.5e-04\t t=22s \tloss=0.219\tval_loss=0.280\tmae=0.283\n",
      "Epoch 76/100 \t lr=2.4e-04\t t=22s \tloss=0.217\tval_loss=0.280\tmae=0.282\n",
      "Epoch 77/100 \t lr=2.3e-04\t t=22s \tloss=0.222\tval_loss=0.282\tmae=0.283\n",
      "Epoch 78/100 \t lr=2.2e-04\t t=22s \tloss=0.240\tval_loss=0.282\tmae=0.284\n",
      "Epoch 79/100 \t lr=2.1e-04\t t=22s \tloss=0.214\tval_loss=0.272\tmae=0.274\n",
      "Epoch 80/100 \t lr=2.0e-04\t t=22s \tloss=0.208\tval_loss=0.269\tmae=0.271\n",
      "Epoch 81/100 \t lr=1.9e-04\t t=22s \tloss=0.208\tval_loss=0.268\tmae=0.270\n",
      "Epoch 82/100 \t lr=1.8e-04\t t=22s \tloss=0.206\tval_loss=0.268\tmae=0.270\n",
      "Epoch 83/100 \t lr=1.7e-04\t t=22s \tloss=0.202\tval_loss=0.268\tmae=0.269\n",
      "Epoch 84/100 \t lr=1.6e-04\t t=22s \tloss=0.200\tval_loss=0.266\tmae=0.267\n",
      "Epoch 85/100 \t lr=1.5e-04\t t=22s \tloss=0.198\tval_loss=0.264\tmae=0.266\n",
      "Epoch 86/100 \t lr=1.4e-04\t t=22s \tloss=0.196\tval_loss=0.265\tmae=0.267\n",
      "Epoch 87/100 \t lr=1.3e-04\t t=22s \tloss=0.195\tval_loss=0.278\tmae=0.277\n",
      "Epoch 88/100 \t lr=1.2e-04\t t=22s \tloss=0.192\tval_loss=0.261\tmae=0.262\n",
      "Epoch 89/100 \t lr=1.1e-04\t t=22s \tloss=0.190\tval_loss=0.259\tmae=0.261\n",
      "Epoch 90/100 \t lr=1.0e-04\t t=22s \tloss=0.188\tval_loss=0.264\tmae=0.266\n",
      "Epoch 91/100 \t lr=9.0e-05\t t=22s \tloss=0.187\tval_loss=0.259\tmae=0.260\n",
      "Epoch 92/100 \t lr=8.0e-05\t t=22s \tloss=0.188\tval_loss=0.261\tmae=0.262\n",
      "Epoch 93/100 \t lr=7.0e-05\t t=22s \tloss=0.184\tval_loss=0.260\tmae=0.261\n",
      "Epoch 94/100 \t lr=6.0e-05\t t=22s \tloss=0.182\tval_loss=0.258\tmae=0.259\n",
      "Epoch 95/100 \t lr=5.0e-05\t t=22s \tloss=0.180\tval_loss=0.256\tmae=0.257\n",
      "Epoch 96/100 \t lr=4.0e-05\t t=22s \tloss=0.179\tval_loss=0.256\tmae=0.257\n",
      "Epoch 97/100 \t lr=3.0e-05\t t=22s \tloss=0.177\tval_loss=0.256\tmae=0.257\n",
      "Epoch 98/100 \t lr=2.0e-05\t t=22s \tloss=0.176\tval_loss=0.254\tmae=0.256\n",
      "Epoch 99/100 \t lr=1.0e-05\t t=22s \tloss=0.175\tval_loss=0.254\tmae=0.256\n",
      "Epoch 100/100 \t lr=0.0e+00\t t=22s \tloss=0.174\tval_loss=0.254\tmae=0.255\n",
      "\n",
      " -> Saving weights to LSTM_1.pt\n",
      "\n",
      "\n",
      "-------------   Fold 3 / 7  -------------\n",
      "\n",
      "    -> 64671 training breathes\n",
      "    -> 10779 validation breathes\n",
      "Epoch 01/100 \t lr=9.9e-04\t t=22s \tloss=3.356\tval_loss=1.428\tmae=1.439\n",
      "Epoch 02/100 \t lr=9.8e-04\t t=22s \tloss=1.292\tval_loss=1.031\tmae=1.040\n",
      "Epoch 03/100 \t lr=9.7e-04\t t=22s \tloss=1.023\tval_loss=0.844\tmae=0.850\n",
      "Epoch 04/100 \t lr=9.6e-04\t t=22s \tloss=0.857\tval_loss=0.779\tmae=0.785\n",
      "Epoch 05/100 \t lr=9.5e-04\t t=22s \tloss=0.792\tval_loss=0.754\tmae=0.759\n",
      "Epoch 06/100 \t lr=9.4e-04\t t=22s \tloss=0.768\tval_loss=0.690\tmae=0.696\n",
      "Epoch 07/100 \t lr=9.3e-04\t t=22s \tloss=0.733\tval_loss=0.686\tmae=0.691\n",
      "Epoch 08/100 \t lr=9.2e-04\t t=22s \tloss=0.660\tval_loss=0.628\tmae=0.632\n",
      "Epoch 09/100 \t lr=9.1e-04\t t=22s \tloss=0.642\tval_loss=0.609\tmae=0.614\n",
      "Epoch 10/100 \t lr=9.0e-04\t t=22s \tloss=0.614\tval_loss=0.591\tmae=0.594\n",
      "Epoch 11/100 \t lr=8.9e-04\t t=22s \tloss=0.601\tval_loss=0.617\tmae=0.620\n",
      "Epoch 12/100 \t lr=8.8e-04\t t=22s \tloss=0.620\tval_loss=0.547\tmae=0.552\n",
      "Epoch 13/100 \t lr=8.7e-04\t t=22s \tloss=0.553\tval_loss=0.536\tmae=0.541\n",
      "Epoch 14/100 \t lr=8.6e-04\t t=22s \tloss=0.573\tval_loss=0.615\tmae=0.619\n",
      "Epoch 15/100 \t lr=8.5e-04\t t=22s \tloss=0.524\tval_loss=0.608\tmae=0.611\n",
      "Epoch 16/100 \t lr=8.4e-04\t t=22s \tloss=0.511\tval_loss=0.552\tmae=0.556\n",
      "Epoch 17/100 \t lr=8.3e-04\t t=22s \tloss=0.498\tval_loss=0.517\tmae=0.521\n",
      "Epoch 18/100 \t lr=8.2e-04\t t=22s \tloss=0.488\tval_loss=0.477\tmae=0.481\n",
      "Epoch 19/100 \t lr=8.1e-04\t t=22s \tloss=0.501\tval_loss=0.492\tmae=0.496\n",
      "Epoch 20/100 \t lr=8.0e-04\t t=22s \tloss=0.499\tval_loss=0.485\tmae=0.490\n",
      "Epoch 21/100 \t lr=7.9e-04\t t=22s \tloss=0.462\tval_loss=0.524\tmae=0.528\n",
      "Epoch 22/100 \t lr=7.8e-04\t t=22s \tloss=0.465\tval_loss=0.486\tmae=0.488\n",
      "Epoch 23/100 \t lr=7.7e-04\t t=22s \tloss=0.450\tval_loss=0.465\tmae=0.468\n",
      "Epoch 24/100 \t lr=7.6e-04\t t=22s \tloss=0.441\tval_loss=0.439\tmae=0.443\n",
      "Epoch 25/100 \t lr=7.5e-04\t t=22s \tloss=0.431\tval_loss=0.451\tmae=0.455\n",
      "Epoch 26/100 \t lr=7.4e-04\t t=22s \tloss=0.431\tval_loss=0.468\tmae=0.471\n",
      "Epoch 27/100 \t lr=7.3e-04\t t=22s \tloss=0.442\tval_loss=0.435\tmae=0.438\n",
      "Epoch 28/100 \t lr=7.2e-04\t t=22s \tloss=0.407\tval_loss=0.471\tmae=0.476\n",
      "Epoch 29/100 \t lr=7.1e-04\t t=22s \tloss=0.423\tval_loss=0.445\tmae=0.449\n",
      "Epoch 30/100 \t lr=7.0e-04\t t=22s \tloss=0.401\tval_loss=0.407\tmae=0.411\n",
      "Epoch 31/100 \t lr=6.9e-04\t t=22s \tloss=0.387\tval_loss=0.407\tmae=0.409\n",
      "Epoch 32/100 \t lr=6.8e-04\t t=22s \tloss=0.388\tval_loss=0.481\tmae=0.484\n",
      "Epoch 33/100 \t lr=6.7e-04\t t=22s \tloss=0.416\tval_loss=0.442\tmae=0.444\n",
      "Epoch 34/100 \t lr=6.6e-04\t t=22s \tloss=0.387\tval_loss=0.425\tmae=0.426\n",
      "Epoch 35/100 \t lr=6.5e-04\t t=22s \tloss=0.387\tval_loss=0.400\tmae=0.403\n",
      "Epoch 36/100 \t lr=6.4e-04\t t=22s \tloss=0.366\tval_loss=0.386\tmae=0.389\n",
      "Epoch 37/100 \t lr=6.3e-04\t t=22s \tloss=0.391\tval_loss=0.383\tmae=0.386\n",
      "Epoch 38/100 \t lr=6.2e-04\t t=22s \tloss=0.356\tval_loss=0.416\tmae=0.420\n",
      "Epoch 39/100 \t lr=6.1e-04\t t=22s \tloss=0.356\tval_loss=0.429\tmae=0.433\n",
      "Epoch 40/100 \t lr=6.0e-04\t t=22s \tloss=0.399\tval_loss=0.390\tmae=0.393\n",
      "Epoch 41/100 \t lr=5.9e-04\t t=22s \tloss=0.352\tval_loss=0.388\tmae=0.390\n",
      "Epoch 42/100 \t lr=5.8e-04\t t=22s \tloss=0.333\tval_loss=0.375\tmae=0.377\n",
      "Epoch 43/100 \t lr=5.7e-04\t t=22s \tloss=0.343\tval_loss=0.401\tmae=0.404\n",
      "Epoch 44/100 \t lr=5.6e-04\t t=22s \tloss=0.358\tval_loss=0.359\tmae=0.361\n",
      "Epoch 45/100 \t lr=5.5e-04\t t=22s \tloss=0.326\tval_loss=0.347\tmae=0.349\n",
      "Epoch 46/100 \t lr=5.4e-04\t t=22s \tloss=0.308\tval_loss=0.346\tmae=0.347\n",
      "Epoch 47/100 \t lr=5.3e-04\t t=22s \tloss=0.317\tval_loss=0.386\tmae=0.390\n",
      "Epoch 48/100 \t lr=5.2e-04\t t=22s \tloss=0.334\tval_loss=0.390\tmae=0.393\n",
      "Epoch 49/100 \t lr=5.1e-04\t t=22s \tloss=0.318\tval_loss=0.362\tmae=0.365\n",
      "Epoch 50/100 \t lr=5.0e-04\t t=22s \tloss=0.305\tval_loss=0.417\tmae=0.422\n",
      "Epoch 51/100 \t lr=4.9e-04\t t=22s \tloss=0.308\tval_loss=0.336\tmae=0.339\n",
      "Epoch 52/100 \t lr=4.8e-04\t t=22s \tloss=0.311\tval_loss=0.383\tmae=0.386\n",
      "Epoch 53/100 \t lr=4.7e-04\t t=22s \tloss=0.304\tval_loss=0.329\tmae=0.332\n",
      "Epoch 54/100 \t lr=4.6e-04\t t=22s \tloss=0.292\tval_loss=0.330\tmae=0.333\n",
      "Epoch 55/100 \t lr=4.5e-04\t t=22s \tloss=0.285\tval_loss=0.336\tmae=0.339\n",
      "Epoch 56/100 \t lr=4.4e-04\t t=22s \tloss=0.269\tval_loss=0.311\tmae=0.314\n",
      "Epoch 57/100 \t lr=4.3e-04\t t=22s \tloss=0.274\tval_loss=0.350\tmae=0.352\n",
      "Epoch 58/100 \t lr=4.2e-04\t t=22s \tloss=0.415\tval_loss=0.371\tmae=0.375\n",
      "Epoch 59/100 \t lr=4.1e-04\t t=22s \tloss=0.345\tval_loss=0.455\tmae=0.460\n",
      "Epoch 60/100 \t lr=4.0e-04\t t=22s \tloss=0.351\tval_loss=0.355\tmae=0.360\n",
      "Epoch 61/100 \t lr=3.9e-04\t t=22s \tloss=0.295\tval_loss=0.325\tmae=0.328\n",
      "Epoch 62/100 \t lr=3.8e-04\t t=22s \tloss=0.284\tval_loss=0.322\tmae=0.325\n",
      "Epoch 63/100 \t lr=3.7e-04\t t=22s \tloss=0.267\tval_loss=0.306\tmae=0.310\n",
      "Epoch 64/100 \t lr=3.6e-04\t t=22s \tloss=0.271\tval_loss=0.311\tmae=0.314\n",
      "Epoch 65/100 \t lr=3.5e-04\t t=22s \tloss=0.259\tval_loss=0.299\tmae=0.302\n",
      "Epoch 66/100 \t lr=3.4e-04\t t=22s \tloss=0.250\tval_loss=0.307\tmae=0.310\n",
      "Epoch 67/100 \t lr=3.3e-04\t t=22s \tloss=0.252\tval_loss=0.309\tmae=0.312\n",
      "Epoch 68/100 \t lr=3.2e-04\t t=22s \tloss=0.246\tval_loss=0.300\tmae=0.303\n",
      "Epoch 69/100 \t lr=3.1e-04\t t=22s \tloss=0.256\tval_loss=0.350\tmae=0.354\n",
      "Epoch 70/100 \t lr=3.0e-04\t t=22s \tloss=0.254\tval_loss=0.297\tmae=0.299\n",
      "Epoch 71/100 \t lr=2.9e-04\t t=22s \tloss=0.239\tval_loss=0.291\tmae=0.294\n",
      "Epoch 72/100 \t lr=2.8e-04\t t=22s \tloss=0.233\tval_loss=0.296\tmae=0.299\n",
      "Epoch 73/100 \t lr=2.7e-04\t t=22s \tloss=0.234\tval_loss=0.294\tmae=0.296\n",
      "Epoch 74/100 \t lr=2.6e-04\t t=22s \tloss=0.227\tval_loss=0.283\tmae=0.285\n",
      "Epoch 75/100 \t lr=2.5e-04\t t=22s \tloss=0.225\tval_loss=0.290\tmae=0.293\n",
      "Epoch 76/100 \t lr=2.4e-04\t t=22s \tloss=0.224\tval_loss=0.293\tmae=0.296\n",
      "Epoch 77/100 \t lr=2.3e-04\t t=22s \tloss=0.220\tval_loss=0.296\tmae=0.300\n",
      "Epoch 78/100 \t lr=2.2e-04\t t=22s \tloss=0.227\tval_loss=0.276\tmae=0.278\n",
      "Epoch 79/100 \t lr=2.1e-04\t t=22s \tloss=0.215\tval_loss=0.272\tmae=0.275\n",
      "Epoch 80/100 \t lr=2.0e-04\t t=22s \tloss=0.213\tval_loss=0.276\tmae=0.278\n",
      "Epoch 81/100 \t lr=1.9e-04\t t=22s \tloss=0.209\tval_loss=0.272\tmae=0.274\n",
      "Epoch 82/100 \t lr=1.8e-04\t t=22s \tloss=0.208\tval_loss=0.269\tmae=0.271\n",
      "Epoch 83/100 \t lr=1.7e-04\t t=22s \tloss=0.206\tval_loss=0.271\tmae=0.273\n",
      "Epoch 84/100 \t lr=1.6e-04\t t=22s \tloss=0.204\tval_loss=0.276\tmae=0.278\n",
      "Epoch 85/100 \t lr=1.5e-04\t t=22s \tloss=0.202\tval_loss=0.269\tmae=0.271\n",
      "Epoch 86/100 \t lr=1.4e-04\t t=22s \tloss=0.198\tval_loss=0.267\tmae=0.270\n",
      "Epoch 87/100 \t lr=1.3e-04\t t=22s \tloss=0.196\tval_loss=0.262\tmae=0.264\n",
      "Epoch 88/100 \t lr=1.2e-04\t t=22s \tloss=0.195\tval_loss=0.264\tmae=0.266\n",
      "Epoch 89/100 \t lr=1.1e-04\t t=22s \tloss=0.192\tval_loss=0.268\tmae=0.270\n",
      "Epoch 90/100 \t lr=1.0e-04\t t=22s \tloss=0.190\tval_loss=0.259\tmae=0.262\n",
      "Epoch 91/100 \t lr=9.0e-05\t t=22s \tloss=0.189\tval_loss=0.263\tmae=0.264\n",
      "Epoch 92/100 \t lr=8.0e-05\t t=22s \tloss=0.186\tval_loss=0.257\tmae=0.260\n",
      "Epoch 93/100 \t lr=7.0e-05\t t=22s \tloss=0.185\tval_loss=0.257\tmae=0.260\n",
      "Epoch 94/100 \t lr=6.0e-05\t t=22s \tloss=0.183\tval_loss=0.256\tmae=0.258\n",
      "Epoch 95/100 \t lr=5.0e-05\t t=22s \tloss=0.181\tval_loss=0.256\tmae=0.258\n",
      "Epoch 96/100 \t lr=4.0e-05\t t=22s \tloss=0.180\tval_loss=0.254\tmae=0.257\n",
      "Epoch 97/100 \t lr=3.0e-05\t t=22s \tloss=0.179\tval_loss=0.255\tmae=0.257\n",
      "Epoch 98/100 \t lr=2.0e-05\t t=22s \tloss=0.177\tval_loss=0.254\tmae=0.256\n",
      "Epoch 99/100 \t lr=1.0e-05\t t=22s \tloss=0.175\tval_loss=0.254\tmae=0.256\n",
      "Epoch 100/100 \t lr=0.0e+00\t t=22s \tloss=0.174\tval_loss=0.253\tmae=0.256\n",
      "\n",
      " -> Saving weights to LSTM_2.pt\n",
      "\n",
      "\n",
      "-------------   Fold 4 / 7  -------------\n",
      "\n",
      "    -> 64671 training breathes\n",
      "    -> 10779 validation breathes\n",
      "Epoch 01/100 \t lr=9.9e-04\t t=22s \tloss=3.339\tval_loss=1.382\tmae=1.393\n",
      "Epoch 02/100 \t lr=9.8e-04\t t=22s \tloss=1.225\tval_loss=1.038\tmae=1.045\n",
      "Epoch 03/100 \t lr=9.7e-04\t t=22s \tloss=0.977\tval_loss=0.932\tmae=0.936\n",
      "Epoch 04/100 \t lr=9.6e-04\t t=22s \tloss=0.858\tval_loss=0.875\tmae=0.879\n",
      "Epoch 05/100 \t lr=9.5e-04\t t=22s \tloss=0.786\tval_loss=0.954\tmae=0.958\n",
      "Epoch 06/100 \t lr=9.4e-04\t t=22s \tloss=0.750\tval_loss=0.699\tmae=0.701\n",
      "Epoch 07/100 \t lr=9.3e-04\t t=22s \tloss=0.718\tval_loss=0.729\tmae=0.733\n",
      "Epoch 08/100 \t lr=9.2e-04\t t=22s \tloss=0.691\tval_loss=0.623\tmae=0.625\n",
      "Epoch 09/100 \t lr=9.1e-04\t t=22s \tloss=0.657\tval_loss=0.657\tmae=0.662\n",
      "Epoch 10/100 \t lr=9.0e-04\t t=22s \tloss=0.634\tval_loss=0.718\tmae=0.719\n",
      "Epoch 11/100 \t lr=8.9e-04\t t=22s \tloss=0.618\tval_loss=0.590\tmae=0.593\n",
      "Epoch 12/100 \t lr=8.8e-04\t t=22s \tloss=0.616\tval_loss=0.570\tmae=0.571\n",
      "Epoch 13/100 \t lr=8.7e-04\t t=22s \tloss=0.582\tval_loss=0.608\tmae=0.608\n",
      "Epoch 14/100 \t lr=8.6e-04\t t=22s \tloss=0.566\tval_loss=0.567\tmae=0.570\n",
      "Epoch 15/100 \t lr=8.5e-04\t t=22s \tloss=0.572\tval_loss=0.544\tmae=0.546\n",
      "Epoch 16/100 \t lr=8.4e-04\t t=22s \tloss=0.537\tval_loss=0.531\tmae=0.534\n",
      "Epoch 17/100 \t lr=8.3e-04\t t=22s \tloss=0.519\tval_loss=0.532\tmae=0.535\n",
      "Epoch 18/100 \t lr=8.2e-04\t t=22s \tloss=0.519\tval_loss=0.517\tmae=0.520\n",
      "Epoch 19/100 \t lr=8.1e-04\t t=22s \tloss=0.507\tval_loss=0.525\tmae=0.528\n",
      "Epoch 20/100 \t lr=8.0e-04\t t=22s \tloss=0.501\tval_loss=0.545\tmae=0.547\n",
      "Epoch 21/100 \t lr=7.9e-04\t t=22s \tloss=0.493\tval_loss=0.485\tmae=0.487\n",
      "Epoch 22/100 \t lr=7.8e-04\t t=22s \tloss=0.473\tval_loss=0.491\tmae=0.491\n",
      "Epoch 23/100 \t lr=7.7e-04\t t=22s \tloss=0.472\tval_loss=0.513\tmae=0.514\n",
      "Epoch 24/100 \t lr=7.6e-04\t t=22s \tloss=0.468\tval_loss=0.472\tmae=0.475\n",
      "Epoch 25/100 \t lr=7.5e-04\t t=22s \tloss=0.472\tval_loss=0.480\tmae=0.481\n",
      "Epoch 26/100 \t lr=7.4e-04\t t=22s \tloss=0.451\tval_loss=0.466\tmae=0.468\n",
      "Epoch 27/100 \t lr=7.3e-04\t t=22s \tloss=0.453\tval_loss=0.560\tmae=0.563\n",
      "Epoch 28/100 \t lr=7.2e-04\t t=22s \tloss=0.437\tval_loss=0.444\tmae=0.445\n",
      "Epoch 29/100 \t lr=7.1e-04\t t=22s \tloss=0.434\tval_loss=0.441\tmae=0.443\n",
      "Epoch 30/100 \t lr=7.0e-04\t t=22s \tloss=0.426\tval_loss=0.493\tmae=0.496\n",
      "Epoch 31/100 \t lr=6.9e-04\t t=22s \tloss=0.407\tval_loss=0.420\tmae=0.422\n",
      "Epoch 32/100 \t lr=6.8e-04\t t=22s \tloss=0.397\tval_loss=0.467\tmae=0.468\n",
      "Epoch 33/100 \t lr=6.7e-04\t t=22s \tloss=0.397\tval_loss=0.514\tmae=0.514\n",
      "Epoch 34/100 \t lr=6.6e-04\t t=22s \tloss=0.395\tval_loss=0.439\tmae=0.440\n",
      "Epoch 35/100 \t lr=6.5e-04\t t=22s \tloss=0.386\tval_loss=0.406\tmae=0.409\n",
      "Epoch 36/100 \t lr=6.4e-04\t t=22s \tloss=0.382\tval_loss=0.521\tmae=0.526\n",
      "Epoch 37/100 \t lr=6.3e-04\t t=22s \tloss=0.382\tval_loss=0.445\tmae=0.447\n",
      "Epoch 38/100 \t lr=6.2e-04\t t=22s \tloss=0.373\tval_loss=0.391\tmae=0.393\n",
      "Epoch 39/100 \t lr=6.1e-04\t t=22s \tloss=0.370\tval_loss=0.403\tmae=0.404\n",
      "Epoch 40/100 \t lr=6.0e-04\t t=22s \tloss=0.357\tval_loss=0.390\tmae=0.393\n",
      "Epoch 41/100 \t lr=5.9e-04\t t=22s \tloss=0.354\tval_loss=0.404\tmae=0.406\n",
      "Epoch 42/100 \t lr=5.8e-04\t t=22s \tloss=0.354\tval_loss=0.396\tmae=0.396\n",
      "Epoch 43/100 \t lr=5.7e-04\t t=22s \tloss=0.352\tval_loss=0.367\tmae=0.369\n",
      "Epoch 44/100 \t lr=5.6e-04\t t=22s \tloss=0.333\tval_loss=0.403\tmae=0.404\n",
      "Epoch 45/100 \t lr=5.5e-04\t t=22s \tloss=0.342\tval_loss=0.360\tmae=0.362\n",
      "Epoch 46/100 \t lr=5.4e-04\t t=22s \tloss=0.343\tval_loss=0.383\tmae=0.383\n",
      "Epoch 47/100 \t lr=5.3e-04\t t=22s \tloss=0.332\tval_loss=0.497\tmae=0.500\n",
      "Epoch 48/100 \t lr=5.2e-04\t t=22s \tloss=0.326\tval_loss=0.364\tmae=0.365\n",
      "Epoch 49/100 \t lr=5.1e-04\t t=22s \tloss=0.309\tval_loss=0.345\tmae=0.348\n",
      "Epoch 50/100 \t lr=5.0e-04\t t=22s \tloss=0.317\tval_loss=0.349\tmae=0.351\n",
      "Epoch 51/100 \t lr=4.9e-04\t t=22s \tloss=0.306\tval_loss=0.341\tmae=0.343\n",
      "Epoch 52/100 \t lr=4.8e-04\t t=22s \tloss=0.297\tval_loss=0.334\tmae=0.336\n",
      "Epoch 53/100 \t lr=4.7e-04\t t=22s \tloss=0.290\tval_loss=0.337\tmae=0.340\n",
      "Epoch 54/100 \t lr=4.6e-04\t t=22s \tloss=0.303\tval_loss=0.355\tmae=0.357\n",
      "Epoch 55/100 \t lr=4.5e-04\t t=22s \tloss=0.314\tval_loss=0.387\tmae=0.390\n",
      "Epoch 56/100 \t lr=4.4e-04\t t=22s \tloss=0.322\tval_loss=0.349\tmae=0.351\n",
      "Epoch 57/100 \t lr=4.3e-04\t t=22s \tloss=0.291\tval_loss=0.314\tmae=0.316\n",
      "Epoch 58/100 \t lr=4.2e-04\t t=22s \tloss=0.279\tval_loss=0.334\tmae=0.335\n",
      "Epoch 59/100 \t lr=4.1e-04\t t=22s \tloss=0.283\tval_loss=0.332\tmae=0.334\n",
      "Epoch 60/100 \t lr=4.0e-04\t t=22s \tloss=0.269\tval_loss=0.344\tmae=0.346\n",
      "Epoch 61/100 \t lr=3.9e-04\t t=22s \tloss=0.291\tval_loss=0.313\tmae=0.315\n",
      "Epoch 62/100 \t lr=3.8e-04\t t=22s \tloss=0.266\tval_loss=0.312\tmae=0.313\n",
      "Epoch 63/100 \t lr=3.7e-04\t t=22s \tloss=0.255\tval_loss=0.304\tmae=0.305\n",
      "Epoch 64/100 \t lr=3.6e-04\t t=22s \tloss=0.289\tval_loss=0.343\tmae=0.345\n",
      "Epoch 65/100 \t lr=3.5e-04\t t=22s \tloss=0.265\tval_loss=0.311\tmae=0.313\n",
      "Epoch 66/100 \t lr=3.4e-04\t t=22s \tloss=0.255\tval_loss=0.306\tmae=0.308\n",
      "Epoch 67/100 \t lr=3.3e-04\t t=22s \tloss=0.279\tval_loss=0.318\tmae=0.321\n",
      "Epoch 68/100 \t lr=3.2e-04\t t=22s \tloss=0.258\tval_loss=0.294\tmae=0.296\n",
      "Epoch 69/100 \t lr=3.1e-04\t t=22s \tloss=0.245\tval_loss=0.303\tmae=0.305\n",
      "Epoch 70/100 \t lr=3.0e-04\t t=22s \tloss=0.241\tval_loss=0.291\tmae=0.293\n",
      "Epoch 71/100 \t lr=2.9e-04\t t=22s \tloss=0.237\tval_loss=0.289\tmae=0.291\n",
      "Epoch 72/100 \t lr=2.8e-04\t t=22s \tloss=0.254\tval_loss=0.331\tmae=0.333\n",
      "Epoch 73/100 \t lr=2.7e-04\t t=22s \tloss=0.259\tval_loss=0.295\tmae=0.297\n",
      "Epoch 74/100 \t lr=2.6e-04\t t=22s \tloss=0.232\tval_loss=0.283\tmae=0.285\n",
      "Epoch 75/100 \t lr=2.5e-04\t t=22s \tloss=0.244\tval_loss=0.295\tmae=0.296\n",
      "Epoch 76/100 \t lr=2.4e-04\t t=22s \tloss=0.231\tval_loss=0.292\tmae=0.295\n",
      "Epoch 77/100 \t lr=2.3e-04\t t=22s \tloss=0.222\tval_loss=0.279\tmae=0.281\n",
      "Epoch 78/100 \t lr=2.2e-04\t t=22s \tloss=0.217\tval_loss=0.277\tmae=0.279\n",
      "Epoch 79/100 \t lr=2.1e-04\t t=22s \tloss=0.217\tval_loss=0.278\tmae=0.279\n",
      "Epoch 80/100 \t lr=2.0e-04\t t=22s \tloss=0.211\tval_loss=0.279\tmae=0.280\n",
      "Epoch 81/100 \t lr=1.9e-04\t t=22s \tloss=0.211\tval_loss=0.277\tmae=0.280\n",
      "Epoch 82/100 \t lr=1.8e-04\t t=22s \tloss=0.209\tval_loss=0.273\tmae=0.274\n",
      "Epoch 83/100 \t lr=1.7e-04\t t=22s \tloss=0.206\tval_loss=0.275\tmae=0.276\n",
      "Epoch 84/100 \t lr=1.6e-04\t t=22s \tloss=0.204\tval_loss=0.287\tmae=0.289\n",
      "Epoch 85/100 \t lr=1.5e-04\t t=22s \tloss=0.202\tval_loss=0.268\tmae=0.269\n",
      "Epoch 86/100 \t lr=1.4e-04\t t=22s \tloss=0.199\tval_loss=0.269\tmae=0.271\n",
      "Epoch 87/100 \t lr=1.3e-04\t t=22s \tloss=0.198\tval_loss=0.268\tmae=0.269\n",
      "Epoch 88/100 \t lr=1.2e-04\t t=22s \tloss=0.206\tval_loss=0.275\tmae=0.276\n",
      "Epoch 89/100 \t lr=1.1e-04\t t=22s \tloss=0.196\tval_loss=0.265\tmae=0.266\n",
      "Epoch 90/100 \t lr=1.0e-04\t t=22s \tloss=0.192\tval_loss=0.266\tmae=0.268\n",
      "Epoch 91/100 \t lr=9.0e-05\t t=22s \tloss=0.190\tval_loss=0.263\tmae=0.264\n",
      "Epoch 92/100 \t lr=8.0e-05\t t=22s \tloss=0.188\tval_loss=0.266\tmae=0.267\n",
      "Epoch 93/100 \t lr=7.0e-05\t t=22s \tloss=0.186\tval_loss=0.261\tmae=0.263\n",
      "Epoch 94/100 \t lr=6.0e-05\t t=22s \tloss=0.186\tval_loss=0.261\tmae=0.262\n",
      "Epoch 95/100 \t lr=5.0e-05\t t=22s \tloss=0.182\tval_loss=0.260\tmae=0.261\n",
      "Epoch 96/100 \t lr=4.0e-05\t t=22s \tloss=0.182\tval_loss=0.261\tmae=0.263\n",
      "Epoch 97/100 \t lr=3.0e-05\t t=22s \tloss=0.179\tval_loss=0.259\tmae=0.260\n",
      "Epoch 98/100 \t lr=2.0e-05\t t=22s \tloss=0.178\tval_loss=0.259\tmae=0.260\n",
      "Epoch 99/100 \t lr=1.0e-05\t t=22s \tloss=0.177\tval_loss=0.258\tmae=0.259\n",
      "Epoch 100/100 \t lr=0.0e+00\t t=22s \tloss=0.175\tval_loss=0.258\tmae=0.259\n",
      "\n",
      " -> Saving weights to LSTM_3.pt\n",
      "\n",
      "\n",
      "-------------   Fold 5 / 7  -------------\n",
      "\n",
      "    -> 64672 training breathes\n",
      "    -> 10778 validation breathes\n",
      "Epoch 01/100 \t lr=9.9e-04\t t=22s \tloss=3.377\tval_loss=1.474\tmae=1.478\n",
      "Epoch 02/100 \t lr=9.8e-04\t t=22s \tloss=1.305\tval_loss=1.068\tmae=1.075\n",
      "Epoch 03/100 \t lr=9.7e-04\t t=22s \tloss=0.983\tval_loss=1.079\tmae=1.082\n",
      "Epoch 04/100 \t lr=9.6e-04\t t=22s \tloss=0.895\tval_loss=0.809\tmae=0.813\n",
      "Epoch 05/100 \t lr=9.5e-04\t t=22s \tloss=0.793\tval_loss=0.742\tmae=0.746\n",
      "Epoch 06/100 \t lr=9.4e-04\t t=22s \tloss=0.738\tval_loss=0.764\tmae=0.769\n",
      "Epoch 07/100 \t lr=9.3e-04\t t=22s \tloss=0.717\tval_loss=0.642\tmae=0.645\n",
      "Epoch 08/100 \t lr=9.2e-04\t t=22s \tloss=0.674\tval_loss=0.619\tmae=0.622\n",
      "Epoch 09/100 \t lr=9.1e-04\t t=22s \tloss=0.642\tval_loss=0.627\tmae=0.631\n",
      "Epoch 10/100 \t lr=9.0e-04\t t=22s \tloss=0.636\tval_loss=0.776\tmae=0.778\n",
      "Epoch 11/100 \t lr=8.9e-04\t t=22s \tloss=0.633\tval_loss=0.697\tmae=0.703\n",
      "Epoch 12/100 \t lr=8.8e-04\t t=22s \tloss=0.597\tval_loss=0.557\tmae=0.560\n",
      "Epoch 13/100 \t lr=8.7e-04\t t=22s \tloss=0.592\tval_loss=0.572\tmae=0.575\n",
      "Epoch 14/100 \t lr=8.6e-04\t t=22s \tloss=0.560\tval_loss=0.545\tmae=0.549\n",
      "Epoch 15/100 \t lr=8.5e-04\t t=22s \tloss=0.556\tval_loss=0.543\tmae=0.546\n",
      "Epoch 16/100 \t lr=8.4e-04\t t=22s \tloss=0.543\tval_loss=0.528\tmae=0.532\n",
      "Epoch 17/100 \t lr=8.3e-04\t t=22s \tloss=0.544\tval_loss=0.516\tmae=0.519\n",
      "Epoch 18/100 \t lr=8.2e-04\t t=22s \tloss=0.534\tval_loss=0.543\tmae=0.548\n",
      "Epoch 19/100 \t lr=8.1e-04\t t=22s \tloss=0.511\tval_loss=0.506\tmae=0.508\n",
      "Epoch 20/100 \t lr=8.0e-04\t t=22s \tloss=0.494\tval_loss=0.470\tmae=0.472\n",
      "Epoch 21/100 \t lr=7.9e-04\t t=22s \tloss=0.487\tval_loss=0.503\tmae=0.505\n",
      "Epoch 22/100 \t lr=7.8e-04\t t=22s \tloss=0.479\tval_loss=0.479\tmae=0.482\n",
      "Epoch 23/100 \t lr=7.7e-04\t t=22s \tloss=0.463\tval_loss=0.469\tmae=0.472\n",
      "Epoch 24/100 \t lr=7.6e-04\t t=22s \tloss=0.475\tval_loss=0.460\tmae=0.462\n",
      "Epoch 25/100 \t lr=7.5e-04\t t=22s \tloss=0.461\tval_loss=0.452\tmae=0.456\n",
      "Epoch 26/100 \t lr=7.4e-04\t t=22s \tloss=0.444\tval_loss=0.461\tmae=0.464\n",
      "Epoch 27/100 \t lr=7.3e-04\t t=22s \tloss=0.441\tval_loss=0.469\tmae=0.473\n",
      "Epoch 28/100 \t lr=7.2e-04\t t=22s \tloss=0.445\tval_loss=0.565\tmae=0.568\n",
      "Epoch 29/100 \t lr=7.1e-04\t t=22s \tloss=0.432\tval_loss=0.432\tmae=0.436\n",
      "Epoch 30/100 \t lr=7.0e-04\t t=22s \tloss=0.413\tval_loss=0.472\tmae=0.475\n",
      "Epoch 31/100 \t lr=6.9e-04\t t=22s \tloss=0.414\tval_loss=0.460\tmae=0.464\n",
      "Epoch 32/100 \t lr=6.8e-04\t t=22s \tloss=0.425\tval_loss=0.425\tmae=0.429\n",
      "Epoch 33/100 \t lr=6.7e-04\t t=22s \tloss=0.409\tval_loss=0.419\tmae=0.423\n",
      "Epoch 34/100 \t lr=6.6e-04\t t=22s \tloss=0.397\tval_loss=0.411\tmae=0.414\n",
      "Epoch 35/100 \t lr=6.5e-04\t t=22s \tloss=0.392\tval_loss=0.413\tmae=0.416\n",
      "Epoch 36/100 \t lr=6.4e-04\t t=22s \tloss=0.385\tval_loss=0.404\tmae=0.407\n",
      "Epoch 37/100 \t lr=6.3e-04\t t=22s \tloss=0.382\tval_loss=0.422\tmae=0.425\n",
      "Epoch 38/100 \t lr=6.2e-04\t t=22s \tloss=0.371\tval_loss=0.404\tmae=0.408\n",
      "Epoch 39/100 \t lr=6.1e-04\t t=22s \tloss=0.402\tval_loss=0.434\tmae=0.438\n",
      "Epoch 40/100 \t lr=6.0e-04\t t=22s \tloss=0.374\tval_loss=0.394\tmae=0.397\n",
      "Epoch 41/100 \t lr=5.9e-04\t t=22s \tloss=0.360\tval_loss=0.464\tmae=0.468\n",
      "Epoch 42/100 \t lr=5.8e-04\t t=22s \tloss=0.380\tval_loss=0.555\tmae=0.559\n",
      "Epoch 43/100 \t lr=5.7e-04\t t=22s \tloss=0.408\tval_loss=0.430\tmae=0.433\n",
      "Epoch 44/100 \t lr=5.6e-04\t t=22s \tloss=0.362\tval_loss=0.389\tmae=0.392\n",
      "Epoch 45/100 \t lr=5.5e-04\t t=22s \tloss=0.350\tval_loss=0.386\tmae=0.388\n",
      "Epoch 46/100 \t lr=5.4e-04\t t=22s \tloss=0.337\tval_loss=0.380\tmae=0.382\n",
      "Epoch 47/100 \t lr=5.3e-04\t t=22s \tloss=0.332\tval_loss=0.369\tmae=0.372\n",
      "Epoch 48/100 \t lr=5.2e-04\t t=22s \tloss=0.320\tval_loss=0.357\tmae=0.358\n",
      "Epoch 49/100 \t lr=5.1e-04\t t=22s \tloss=0.356\tval_loss=0.398\tmae=0.402\n",
      "Epoch 50/100 \t lr=5.0e-04\t t=22s \tloss=0.337\tval_loss=0.369\tmae=0.373\n",
      "Epoch 51/100 \t lr=4.9e-04\t t=22s \tloss=0.367\tval_loss=0.375\tmae=0.377\n",
      "Epoch 52/100 \t lr=4.8e-04\t t=22s \tloss=0.325\tval_loss=0.345\tmae=0.347\n",
      "Epoch 53/100 \t lr=4.7e-04\t t=22s \tloss=0.315\tval_loss=0.330\tmae=0.333\n",
      "Epoch 54/100 \t lr=4.6e-04\t t=22s \tloss=0.300\tval_loss=0.328\tmae=0.331\n",
      "Epoch 55/100 \t lr=4.5e-04\t t=22s \tloss=0.318\tval_loss=0.399\tmae=0.401\n",
      "Epoch 56/100 \t lr=4.4e-04\t t=22s \tloss=0.315\tval_loss=0.331\tmae=0.333\n",
      "Epoch 57/100 \t lr=4.3e-04\t t=22s \tloss=0.302\tval_loss=0.337\tmae=0.339\n",
      "Epoch 58/100 \t lr=4.2e-04\t t=22s \tloss=0.294\tval_loss=0.351\tmae=0.353\n",
      "Epoch 59/100 \t lr=4.1e-04\t t=22s \tloss=0.290\tval_loss=0.315\tmae=0.318\n",
      "Epoch 60/100 \t lr=4.0e-04\t t=22s \tloss=0.283\tval_loss=0.330\tmae=0.332\n",
      "Epoch 61/100 \t lr=3.9e-04\t t=22s \tloss=0.281\tval_loss=0.349\tmae=0.352\n",
      "Epoch 62/100 \t lr=3.8e-04\t t=22s \tloss=0.278\tval_loss=0.310\tmae=0.313\n",
      "Epoch 63/100 \t lr=3.7e-04\t t=22s \tloss=0.275\tval_loss=0.313\tmae=0.315\n",
      "Epoch 64/100 \t lr=3.6e-04\t t=22s \tloss=0.268\tval_loss=0.298\tmae=0.301\n",
      "Epoch 65/100 \t lr=3.5e-04\t t=22s \tloss=0.262\tval_loss=0.324\tmae=0.327\n",
      "Epoch 66/100 \t lr=3.4e-04\t t=22s \tloss=0.263\tval_loss=0.311\tmae=0.313\n",
      "Epoch 67/100 \t lr=3.3e-04\t t=22s \tloss=0.253\tval_loss=0.294\tmae=0.296\n",
      "Epoch 68/100 \t lr=3.2e-04\t t=22s \tloss=0.252\tval_loss=0.297\tmae=0.298\n",
      "Epoch 69/100 \t lr=3.1e-04\t t=22s \tloss=0.253\tval_loss=0.298\tmae=0.299\n",
      "Epoch 70/100 \t lr=3.0e-04\t t=22s \tloss=0.252\tval_loss=0.295\tmae=0.298\n",
      "Epoch 71/100 \t lr=2.9e-04\t t=22s \tloss=0.245\tval_loss=0.289\tmae=0.292\n",
      "Epoch 72/100 \t lr=2.8e-04\t t=22s \tloss=0.248\tval_loss=0.370\tmae=0.372\n",
      "Epoch 73/100 \t lr=2.7e-04\t t=22s \tloss=0.251\tval_loss=0.333\tmae=0.337\n",
      "Epoch 74/100 \t lr=2.6e-04\t t=22s \tloss=0.243\tval_loss=0.289\tmae=0.291\n",
      "Epoch 75/100 \t lr=2.5e-04\t t=22s \tloss=0.233\tval_loss=0.282\tmae=0.283\n",
      "Epoch 76/100 \t lr=2.4e-04\t t=22s \tloss=0.227\tval_loss=0.279\tmae=0.281\n",
      "Epoch 77/100 \t lr=2.3e-04\t t=22s \tloss=0.227\tval_loss=0.276\tmae=0.278\n",
      "Epoch 78/100 \t lr=2.2e-04\t t=22s \tloss=0.224\tval_loss=0.282\tmae=0.284\n",
      "Epoch 79/100 \t lr=2.1e-04\t t=22s \tloss=0.222\tval_loss=0.281\tmae=0.283\n",
      "Epoch 80/100 \t lr=2.0e-04\t t=22s \tloss=0.218\tval_loss=0.281\tmae=0.282\n",
      "Epoch 81/100 \t lr=1.9e-04\t t=22s \tloss=0.215\tval_loss=0.272\tmae=0.274\n",
      "Epoch 82/100 \t lr=1.8e-04\t t=22s \tloss=0.214\tval_loss=0.268\tmae=0.270\n",
      "Epoch 83/100 \t lr=1.7e-04\t t=22s \tloss=0.211\tval_loss=0.276\tmae=0.279\n",
      "Epoch 84/100 \t lr=1.6e-04\t t=22s \tloss=0.212\tval_loss=0.271\tmae=0.272\n",
      "Epoch 85/100 \t lr=1.5e-04\t t=22s \tloss=0.209\tval_loss=0.274\tmae=0.275\n",
      "Epoch 86/100 \t lr=1.4e-04\t t=22s \tloss=0.205\tval_loss=0.267\tmae=0.268\n",
      "Epoch 87/100 \t lr=1.3e-04\t t=22s \tloss=0.203\tval_loss=0.266\tmae=0.268\n",
      "Epoch 88/100 \t lr=1.2e-04\t t=22s \tloss=0.200\tval_loss=0.278\tmae=0.279\n",
      "Epoch 89/100 \t lr=1.1e-04\t t=22s \tloss=0.199\tval_loss=0.263\tmae=0.264\n",
      "Epoch 90/100 \t lr=1.0e-04\t t=22s \tloss=0.196\tval_loss=0.261\tmae=0.263\n",
      "Epoch 91/100 \t lr=9.0e-05\t t=22s \tloss=0.194\tval_loss=0.263\tmae=0.264\n",
      "Epoch 92/100 \t lr=8.0e-05\t t=22s \tloss=0.193\tval_loss=0.260\tmae=0.261\n",
      "Epoch 93/100 \t lr=7.0e-05\t t=22s \tloss=0.191\tval_loss=0.259\tmae=0.261\n",
      "Epoch 94/100 \t lr=6.0e-05\t t=22s \tloss=0.189\tval_loss=0.258\tmae=0.260\n",
      "Epoch 95/100 \t lr=5.0e-05\t t=22s \tloss=0.188\tval_loss=0.259\tmae=0.261\n",
      "Epoch 96/100 \t lr=4.0e-05\t t=22s \tloss=0.186\tval_loss=0.258\tmae=0.259\n",
      "Epoch 97/100 \t lr=3.0e-05\t t=22s \tloss=0.184\tval_loss=0.257\tmae=0.258\n",
      "Epoch 98/100 \t lr=2.0e-05\t t=22s \tloss=0.183\tval_loss=0.257\tmae=0.258\n",
      "Epoch 99/100 \t lr=1.0e-05\t t=22s \tloss=0.182\tval_loss=0.256\tmae=0.257\n",
      "Epoch 100/100 \t lr=0.0e+00\t t=22s \tloss=0.180\tval_loss=0.256\tmae=0.257\n",
      "\n",
      " -> Saving weights to LSTM_4.pt\n",
      "\n",
      "\n",
      "-------------   Fold 6 / 7  -------------\n",
      "\n",
      "    -> 64672 training breathes\n",
      "    -> 10778 validation breathes\n",
      "Epoch 01/100 \t lr=9.9e-04\t t=22s \tloss=3.457\tval_loss=1.662\tmae=1.666\n",
      "Epoch 02/100 \t lr=9.8e-04\t t=22s \tloss=1.378\tval_loss=1.133\tmae=1.137\n",
      "Epoch 03/100 \t lr=9.7e-04\t t=22s \tloss=1.090\tval_loss=0.893\tmae=0.899\n",
      "Epoch 04/100 \t lr=9.6e-04\t t=22s \tloss=0.891\tval_loss=0.814\tmae=0.817\n",
      "Epoch 05/100 \t lr=9.5e-04\t t=22s \tloss=0.789\tval_loss=0.841\tmae=0.844\n",
      "Epoch 06/100 \t lr=9.4e-04\t t=22s \tloss=0.761\tval_loss=0.705\tmae=0.708\n",
      "Epoch 07/100 \t lr=9.3e-04\t t=22s \tloss=0.711\tval_loss=0.661\tmae=0.665\n",
      "Epoch 08/100 \t lr=9.2e-04\t t=22s \tloss=0.670\tval_loss=0.639\tmae=0.643\n",
      "Epoch 09/100 \t lr=9.1e-04\t t=22s \tloss=0.652\tval_loss=0.614\tmae=0.618\n",
      "Epoch 10/100 \t lr=9.0e-04\t t=22s \tloss=0.619\tval_loss=0.600\tmae=0.602\n",
      "Epoch 11/100 \t lr=8.9e-04\t t=22s \tloss=0.649\tval_loss=0.587\tmae=0.591\n",
      "Epoch 12/100 \t lr=8.8e-04\t t=22s \tloss=0.576\tval_loss=0.570\tmae=0.573\n",
      "Epoch 13/100 \t lr=8.7e-04\t t=22s \tloss=0.568\tval_loss=0.571\tmae=0.574\n",
      "Epoch 14/100 \t lr=8.6e-04\t t=22s \tloss=0.559\tval_loss=0.552\tmae=0.556\n",
      "Epoch 15/100 \t lr=8.5e-04\t t=22s \tloss=0.544\tval_loss=0.602\tmae=0.606\n",
      "Epoch 16/100 \t lr=8.4e-04\t t=22s \tloss=0.542\tval_loss=0.543\tmae=0.547\n",
      "Epoch 17/100 \t lr=8.3e-04\t t=22s \tloss=0.525\tval_loss=0.536\tmae=0.539\n",
      "Epoch 18/100 \t lr=8.2e-04\t t=22s \tloss=0.533\tval_loss=0.496\tmae=0.499\n",
      "Epoch 19/100 \t lr=8.1e-04\t t=22s \tloss=0.490\tval_loss=0.503\tmae=0.507\n",
      "Epoch 20/100 \t lr=8.0e-04\t t=22s \tloss=0.487\tval_loss=0.616\tmae=0.620\n",
      "Epoch 21/100 \t lr=7.9e-04\t t=22s \tloss=0.485\tval_loss=0.499\tmae=0.502\n",
      "Epoch 22/100 \t lr=7.8e-04\t t=22s \tloss=0.469\tval_loss=0.478\tmae=0.483\n",
      "Epoch 23/100 \t lr=7.7e-04\t t=22s \tloss=0.463\tval_loss=0.490\tmae=0.493\n",
      "Epoch 24/100 \t lr=7.6e-04\t t=22s \tloss=0.451\tval_loss=0.473\tmae=0.477\n",
      "Epoch 25/100 \t lr=7.5e-04\t t=22s \tloss=0.455\tval_loss=0.492\tmae=0.494\n",
      "Epoch 26/100 \t lr=7.4e-04\t t=22s \tloss=0.441\tval_loss=0.451\tmae=0.454\n",
      "Epoch 27/100 \t lr=7.3e-04\t t=22s \tloss=0.428\tval_loss=0.441\tmae=0.445\n",
      "Epoch 28/100 \t lr=7.2e-04\t t=22s \tloss=0.434\tval_loss=0.476\tmae=0.479\n",
      "Epoch 29/100 \t lr=7.1e-04\t t=22s \tloss=0.416\tval_loss=0.420\tmae=0.423\n",
      "Epoch 30/100 \t lr=7.0e-04\t t=22s \tloss=0.415\tval_loss=0.422\tmae=0.424\n",
      "Epoch 31/100 \t lr=6.9e-04\t t=22s \tloss=0.408\tval_loss=0.441\tmae=0.444\n",
      "Epoch 32/100 \t lr=6.8e-04\t t=22s \tloss=0.402\tval_loss=0.435\tmae=0.437\n",
      "Epoch 33/100 \t lr=6.7e-04\t t=22s \tloss=0.398\tval_loss=0.431\tmae=0.434\n",
      "Epoch 34/100 \t lr=6.6e-04\t t=22s \tloss=0.400\tval_loss=0.427\tmae=0.430\n",
      "Epoch 35/100 \t lr=6.5e-04\t t=22s \tloss=0.435\tval_loss=0.516\tmae=0.520\n",
      "Epoch 36/100 \t lr=6.4e-04\t t=22s \tloss=0.420\tval_loss=0.420\tmae=0.423\n",
      "Epoch 37/100 \t lr=6.3e-04\t t=22s \tloss=0.387\tval_loss=0.396\tmae=0.399\n",
      "Epoch 38/100 \t lr=6.2e-04\t t=22s \tloss=0.396\tval_loss=0.416\tmae=0.420\n",
      "Epoch 39/100 \t lr=6.1e-04\t t=22s \tloss=0.364\tval_loss=0.377\tmae=0.380\n",
      "Epoch 40/100 \t lr=6.0e-04\t t=22s \tloss=0.369\tval_loss=0.403\tmae=0.406\n",
      "Epoch 41/100 \t lr=5.9e-04\t t=22s \tloss=0.365\tval_loss=0.369\tmae=0.372\n",
      "Epoch 42/100 \t lr=5.8e-04\t t=22s \tloss=0.344\tval_loss=0.384\tmae=0.388\n",
      "Epoch 43/100 \t lr=5.7e-04\t t=22s \tloss=0.373\tval_loss=0.380\tmae=0.383\n",
      "Epoch 44/100 \t lr=5.6e-04\t t=22s \tloss=0.343\tval_loss=0.384\tmae=0.387\n",
      "Epoch 45/100 \t lr=5.5e-04\t t=22s \tloss=0.463\tval_loss=0.390\tmae=0.393\n",
      "Epoch 46/100 \t lr=5.4e-04\t t=22s \tloss=0.357\tval_loss=0.374\tmae=0.377\n",
      "Epoch 47/100 \t lr=5.3e-04\t t=21s \tloss=0.340\tval_loss=0.368\tmae=0.372\n",
      "Epoch 48/100 \t lr=5.2e-04\t t=21s \tloss=0.340\tval_loss=0.357\tmae=0.361\n",
      "Epoch 49/100 \t lr=5.1e-04\t t=21s \tloss=0.328\tval_loss=0.343\tmae=0.346\n",
      "Epoch 50/100 \t lr=5.0e-04\t t=21s \tloss=0.310\tval_loss=0.357\tmae=0.360\n",
      "Epoch 51/100 \t lr=4.9e-04\t t=22s \tloss=0.352\tval_loss=0.346\tmae=0.348\n",
      "Epoch 52/100 \t lr=4.8e-04\t t=22s \tloss=0.329\tval_loss=0.341\tmae=0.343\n",
      "Epoch 53/100 \t lr=4.7e-04\t t=21s \tloss=0.309\tval_loss=0.355\tmae=0.357\n",
      "Epoch 54/100 \t lr=4.6e-04\t t=21s \tloss=0.300\tval_loss=0.332\tmae=0.334\n",
      "Epoch 55/100 \t lr=4.5e-04\t t=21s \tloss=0.305\tval_loss=0.347\tmae=0.351\n",
      "Epoch 56/100 \t lr=4.4e-04\t t=22s \tloss=0.317\tval_loss=0.347\tmae=0.350\n",
      "Epoch 57/100 \t lr=4.3e-04\t t=21s \tloss=0.301\tval_loss=0.330\tmae=0.333\n",
      "Epoch 58/100 \t lr=4.2e-04\t t=22s \tloss=0.290\tval_loss=0.313\tmae=0.315\n",
      "Epoch 59/100 \t lr=4.1e-04\t t=22s \tloss=0.278\tval_loss=0.326\tmae=0.329\n",
      "Epoch 60/100 \t lr=4.0e-04\t t=22s \tloss=0.287\tval_loss=0.319\tmae=0.322\n",
      "Epoch 61/100 \t lr=3.9e-04\t t=22s \tloss=0.274\tval_loss=0.304\tmae=0.307\n",
      "Epoch 62/100 \t lr=3.8e-04\t t=22s \tloss=0.269\tval_loss=0.305\tmae=0.307\n",
      "Epoch 63/100 \t lr=3.7e-04\t t=22s \tloss=0.272\tval_loss=0.299\tmae=0.302\n",
      "Epoch 64/100 \t lr=3.6e-04\t t=22s \tloss=0.266\tval_loss=0.315\tmae=0.317\n",
      "Epoch 65/100 \t lr=3.5e-04\t t=22s \tloss=0.258\tval_loss=0.319\tmae=0.320\n",
      "Epoch 66/100 \t lr=3.4e-04\t t=22s \tloss=0.255\tval_loss=0.301\tmae=0.303\n",
      "Epoch 67/100 \t lr=3.3e-04\t t=22s \tloss=0.287\tval_loss=0.325\tmae=0.328\n",
      "Epoch 68/100 \t lr=3.2e-04\t t=22s \tloss=0.273\tval_loss=0.332\tmae=0.335\n",
      "Epoch 69/100 \t lr=3.1e-04\t t=22s \tloss=0.262\tval_loss=0.316\tmae=0.319\n",
      "Epoch 70/100 \t lr=3.0e-04\t t=22s \tloss=0.258\tval_loss=0.295\tmae=0.297\n",
      "Epoch 71/100 \t lr=2.9e-04\t t=22s \tloss=0.256\tval_loss=0.295\tmae=0.298\n",
      "Epoch 72/100 \t lr=2.8e-04\t t=22s \tloss=0.282\tval_loss=0.343\tmae=0.344\n",
      "Epoch 73/100 \t lr=2.7e-04\t t=22s \tloss=0.252\tval_loss=0.286\tmae=0.289\n",
      "Epoch 74/100 \t lr=2.6e-04\t t=22s \tloss=0.241\tval_loss=0.295\tmae=0.297\n",
      "Epoch 75/100 \t lr=2.5e-04\t t=22s \tloss=0.251\tval_loss=0.299\tmae=0.301\n",
      "Epoch 76/100 \t lr=2.4e-04\t t=22s \tloss=0.234\tval_loss=0.298\tmae=0.301\n",
      "Epoch 77/100 \t lr=2.3e-04\t t=22s \tloss=0.228\tval_loss=0.280\tmae=0.282\n",
      "Epoch 78/100 \t lr=2.2e-04\t t=22s \tloss=0.223\tval_loss=0.279\tmae=0.282\n",
      "Epoch 79/100 \t lr=2.1e-04\t t=22s \tloss=0.220\tval_loss=0.275\tmae=0.277\n",
      "Epoch 80/100 \t lr=2.0e-04\t t=22s \tloss=0.218\tval_loss=0.284\tmae=0.286\n",
      "Epoch 81/100 \t lr=1.9e-04\t t=22s \tloss=0.218\tval_loss=0.268\tmae=0.270\n",
      "Epoch 82/100 \t lr=1.8e-04\t t=22s \tloss=0.237\tval_loss=0.353\tmae=0.358\n",
      "Epoch 83/100 \t lr=1.7e-04\t t=22s \tloss=0.239\tval_loss=0.273\tmae=0.275\n",
      "Epoch 84/100 \t lr=1.6e-04\t t=22s \tloss=0.215\tval_loss=0.271\tmae=0.274\n",
      "Epoch 85/100 \t lr=1.5e-04\t t=22s \tloss=0.214\tval_loss=0.266\tmae=0.269\n",
      "Epoch 86/100 \t lr=1.4e-04\t t=22s \tloss=0.209\tval_loss=0.263\tmae=0.266\n",
      "Epoch 87/100 \t lr=1.3e-04\t t=22s \tloss=0.204\tval_loss=0.263\tmae=0.265\n",
      "Epoch 88/100 \t lr=1.2e-04\t t=22s \tloss=0.201\tval_loss=0.260\tmae=0.262\n",
      "Epoch 89/100 \t lr=1.1e-04\t t=22s \tloss=0.200\tval_loss=0.260\tmae=0.262\n",
      "Epoch 90/100 \t lr=1.0e-04\t t=22s \tloss=0.199\tval_loss=0.258\tmae=0.260\n",
      "Epoch 91/100 \t lr=9.0e-05\t t=22s \tloss=0.196\tval_loss=0.257\tmae=0.259\n",
      "Epoch 92/100 \t lr=8.0e-05\t t=22s \tloss=0.194\tval_loss=0.256\tmae=0.258\n",
      "Epoch 93/100 \t lr=7.0e-05\t t=22s \tloss=0.192\tval_loss=0.255\tmae=0.257\n",
      "Epoch 94/100 \t lr=6.0e-05\t t=22s \tloss=0.190\tval_loss=0.255\tmae=0.258\n",
      "Epoch 95/100 \t lr=5.0e-05\t t=22s \tloss=0.189\tval_loss=0.254\tmae=0.256\n",
      "Epoch 96/100 \t lr=4.0e-05\t t=22s \tloss=0.187\tval_loss=0.254\tmae=0.256\n",
      "Epoch 97/100 \t lr=3.0e-05\t t=22s \tloss=0.185\tval_loss=0.252\tmae=0.254\n",
      "Epoch 98/100 \t lr=2.0e-05\t t=22s \tloss=0.184\tval_loss=0.251\tmae=0.253\n",
      "Epoch 99/100 \t lr=1.0e-05\t t=22s \tloss=0.183\tval_loss=0.252\tmae=0.254\n",
      "Epoch 100/100 \t lr=0.0e+00\t t=22s \tloss=0.182\tval_loss=0.251\tmae=0.253\n",
      "\n",
      " -> Saving weights to LSTM_5.pt\n",
      "\n",
      "\n",
      "-------------   Fold 7 / 7  -------------\n",
      "\n",
      "    -> 64672 training breathes\n",
      "    -> 10778 validation breathes\n",
      "Epoch 01/100 \t lr=9.9e-04\t t=22s \tloss=3.315\tval_loss=1.557\tmae=1.563\n",
      "Epoch 02/100 \t lr=9.8e-04\t t=22s \tloss=1.270\tval_loss=1.037\tmae=1.044\n",
      "Epoch 03/100 \t lr=9.7e-04\t t=22s \tloss=0.967\tval_loss=0.996\tmae=1.003\n",
      "Epoch 04/100 \t lr=9.6e-04\t t=21s \tloss=0.863\tval_loss=0.762\tmae=0.767\n",
      "Epoch 05/100 \t lr=9.5e-04\t t=21s \tloss=0.801\tval_loss=0.788\tmae=0.794\n",
      "Epoch 06/100 \t lr=9.4e-04\t t=21s \tloss=0.748\tval_loss=0.660\tmae=0.665\n",
      "Epoch 07/100 \t lr=9.3e-04\t t=22s \tloss=0.713\tval_loss=0.651\tmae=0.657\n",
      "Epoch 08/100 \t lr=9.2e-04\t t=22s \tloss=0.683\tval_loss=0.631\tmae=0.638\n",
      "Epoch 09/100 \t lr=9.1e-04\t t=22s \tloss=0.638\tval_loss=0.627\tmae=0.633\n",
      "Epoch 10/100 \t lr=9.0e-04\t t=22s \tloss=0.636\tval_loss=0.602\tmae=0.608\n",
      "Epoch 11/100 \t lr=8.9e-04\t t=21s \tloss=0.593\tval_loss=0.611\tmae=0.616\n",
      "Epoch 12/100 \t lr=8.8e-04\t t=21s \tloss=0.594\tval_loss=0.656\tmae=0.661\n",
      "Epoch 13/100 \t lr=8.7e-04\t t=22s \tloss=0.596\tval_loss=0.566\tmae=0.571\n",
      "Epoch 14/100 \t lr=8.6e-04\t t=22s \tloss=0.567\tval_loss=0.602\tmae=0.607\n",
      "Epoch 15/100 \t lr=8.5e-04\t t=21s \tloss=0.539\tval_loss=0.533\tmae=0.538\n",
      "Epoch 16/100 \t lr=8.4e-04\t t=21s \tloss=0.533\tval_loss=0.529\tmae=0.535\n",
      "Epoch 17/100 \t lr=8.3e-04\t t=21s \tloss=0.519\tval_loss=0.507\tmae=0.513\n",
      "Epoch 18/100 \t lr=8.2e-04\t t=21s \tloss=0.522\tval_loss=0.495\tmae=0.500\n",
      "Epoch 19/100 \t lr=8.1e-04\t t=21s \tloss=0.509\tval_loss=0.495\tmae=0.501\n",
      "Epoch 20/100 \t lr=8.0e-04\t t=21s \tloss=0.499\tval_loss=0.482\tmae=0.488\n",
      "Epoch 21/100 \t lr=7.9e-04\t t=21s \tloss=0.476\tval_loss=0.479\tmae=0.484\n",
      "Epoch 22/100 \t lr=7.8e-04\t t=22s \tloss=0.480\tval_loss=0.458\tmae=0.462\n",
      "Epoch 23/100 \t lr=7.7e-04\t t=22s \tloss=0.471\tval_loss=0.490\tmae=0.495\n",
      "Epoch 24/100 \t lr=7.6e-04\t t=21s \tloss=0.454\tval_loss=0.493\tmae=0.497\n",
      "Epoch 25/100 \t lr=7.5e-04\t t=22s \tloss=0.458\tval_loss=0.450\tmae=0.455\n",
      "Epoch 26/100 \t lr=7.4e-04\t t=22s \tloss=0.448\tval_loss=0.509\tmae=0.513\n",
      "Epoch 27/100 \t lr=7.3e-04\t t=22s \tloss=0.439\tval_loss=0.440\tmae=0.444\n",
      "Epoch 28/100 \t lr=7.2e-04\t t=22s \tloss=0.433\tval_loss=0.462\tmae=0.466\n",
      "Epoch 29/100 \t lr=7.1e-04\t t=22s \tloss=0.420\tval_loss=0.474\tmae=0.479\n",
      "Epoch 30/100 \t lr=7.0e-04\t t=22s \tloss=0.418\tval_loss=0.502\tmae=0.506\n",
      "Epoch 31/100 \t lr=6.9e-04\t t=21s \tloss=0.405\tval_loss=0.438\tmae=0.443\n",
      "Epoch 32/100 \t lr=6.8e-04\t t=22s \tloss=0.402\tval_loss=0.432\tmae=0.436\n",
      "Epoch 33/100 \t lr=6.7e-04\t t=21s \tloss=0.399\tval_loss=0.411\tmae=0.415\n",
      "Epoch 34/100 \t lr=6.6e-04\t t=22s \tloss=0.396\tval_loss=0.417\tmae=0.422\n",
      "Epoch 35/100 \t lr=6.5e-04\t t=21s \tloss=0.389\tval_loss=0.424\tmae=0.428\n",
      "Epoch 36/100 \t lr=6.4e-04\t t=21s \tloss=0.378\tval_loss=0.419\tmae=0.424\n",
      "Epoch 37/100 \t lr=6.3e-04\t t=21s \tloss=0.374\tval_loss=0.390\tmae=0.394\n",
      "Epoch 38/100 \t lr=6.2e-04\t t=22s \tloss=0.369\tval_loss=0.377\tmae=0.381\n",
      "Epoch 39/100 \t lr=6.1e-04\t t=22s \tloss=0.364\tval_loss=0.402\tmae=0.407\n",
      "Epoch 40/100 \t lr=6.0e-04\t t=22s \tloss=0.354\tval_loss=0.374\tmae=0.378\n",
      "Epoch 41/100 \t lr=5.9e-04\t t=22s \tloss=0.355\tval_loss=0.371\tmae=0.375\n",
      "Epoch 42/100 \t lr=5.8e-04\t t=21s \tloss=0.345\tval_loss=0.416\tmae=0.420\n",
      "Epoch 43/100 \t lr=5.7e-04\t t=21s \tloss=0.383\tval_loss=0.424\tmae=0.427\n",
      "Epoch 44/100 \t lr=5.6e-04\t t=21s \tloss=0.358\tval_loss=0.384\tmae=0.388\n",
      "Epoch 45/100 \t lr=5.5e-04\t t=21s \tloss=0.340\tval_loss=0.355\tmae=0.359\n",
      "Epoch 46/100 \t lr=5.4e-04\t t=21s \tloss=0.329\tval_loss=0.357\tmae=0.362\n",
      "Epoch 47/100 \t lr=5.3e-04\t t=21s \tloss=0.341\tval_loss=0.354\tmae=0.358\n",
      "Epoch 48/100 \t lr=5.2e-04\t t=21s \tloss=0.333\tval_loss=0.377\tmae=0.380\n",
      "Epoch 49/100 \t lr=5.1e-04\t t=22s \tloss=0.329\tval_loss=0.375\tmae=0.379\n",
      "Epoch 50/100 \t lr=5.0e-04\t t=22s \tloss=0.359\tval_loss=0.351\tmae=0.355\n",
      "Epoch 51/100 \t lr=4.9e-04\t t=22s \tloss=0.318\tval_loss=0.335\tmae=0.339\n",
      "Epoch 52/100 \t lr=4.8e-04\t t=21s \tloss=0.312\tval_loss=0.341\tmae=0.345\n",
      "Epoch 53/100 \t lr=4.7e-04\t t=22s \tloss=0.312\tval_loss=0.344\tmae=0.349\n",
      "Epoch 54/100 \t lr=4.6e-04\t t=21s \tloss=0.305\tval_loss=0.357\tmae=0.362\n",
      "Epoch 55/100 \t lr=4.5e-04\t t=21s \tloss=0.306\tval_loss=0.337\tmae=0.341\n",
      "Epoch 56/100 \t lr=4.4e-04\t t=22s \tloss=0.292\tval_loss=0.360\tmae=0.363\n",
      "Epoch 57/100 \t lr=4.3e-04\t t=22s \tloss=0.285\tval_loss=0.326\tmae=0.329\n",
      "Epoch 58/100 \t lr=4.2e-04\t t=22s \tloss=0.281\tval_loss=0.321\tmae=0.325\n",
      "Epoch 59/100 \t lr=4.1e-04\t t=22s \tloss=0.280\tval_loss=0.324\tmae=0.327\n",
      "Epoch 60/100 \t lr=4.0e-04\t t=22s \tloss=0.278\tval_loss=0.319\tmae=0.323\n",
      "Epoch 61/100 \t lr=3.9e-04\t t=22s \tloss=0.278\tval_loss=0.343\tmae=0.346\n",
      "Epoch 62/100 \t lr=3.8e-04\t t=22s \tloss=0.300\tval_loss=0.381\tmae=0.384\n",
      "Epoch 63/100 \t lr=3.7e-04\t t=22s \tloss=0.287\tval_loss=0.340\tmae=0.344\n",
      "Epoch 64/100 \t lr=3.6e-04\t t=22s \tloss=0.270\tval_loss=0.310\tmae=0.314\n",
      "Epoch 65/100 \t lr=3.5e-04\t t=21s \tloss=0.264\tval_loss=0.303\tmae=0.307\n",
      "Epoch 66/100 \t lr=3.4e-04\t t=22s \tloss=0.254\tval_loss=0.304\tmae=0.308\n",
      "Epoch 67/100 \t lr=3.3e-04\t t=22s \tloss=0.253\tval_loss=0.304\tmae=0.308\n",
      "Epoch 68/100 \t lr=3.2e-04\t t=22s \tloss=0.270\tval_loss=0.314\tmae=0.318\n",
      "Epoch 69/100 \t lr=3.1e-04\t t=22s \tloss=0.258\tval_loss=0.315\tmae=0.319\n",
      "Epoch 70/100 \t lr=3.0e-04\t t=22s \tloss=0.250\tval_loss=0.290\tmae=0.293\n",
      "Epoch 71/100 \t lr=2.9e-04\t t=22s \tloss=0.240\tval_loss=0.293\tmae=0.297\n",
      "Epoch 72/100 \t lr=2.8e-04\t t=22s \tloss=0.239\tval_loss=0.299\tmae=0.302\n",
      "Epoch 73/100 \t lr=2.7e-04\t t=22s \tloss=0.241\tval_loss=0.290\tmae=0.293\n",
      "Epoch 74/100 \t lr=2.6e-04\t t=22s \tloss=0.239\tval_loss=0.311\tmae=0.315\n",
      "Epoch 75/100 \t lr=2.5e-04\t t=22s \tloss=0.247\tval_loss=0.296\tmae=0.299\n",
      "Epoch 76/100 \t lr=2.4e-04\t t=21s \tloss=0.232\tval_loss=0.284\tmae=0.287\n",
      "Epoch 77/100 \t lr=2.3e-04\t t=22s \tloss=0.234\tval_loss=0.288\tmae=0.291\n",
      "Epoch 78/100 \t lr=2.2e-04\t t=22s \tloss=0.233\tval_loss=0.283\tmae=0.286\n",
      "Epoch 79/100 \t lr=2.1e-04\t t=22s \tloss=0.222\tval_loss=0.281\tmae=0.284\n",
      "Epoch 80/100 \t lr=2.0e-04\t t=22s \tloss=0.220\tval_loss=0.290\tmae=0.293\n",
      "Epoch 81/100 \t lr=1.9e-04\t t=22s \tloss=0.217\tval_loss=0.284\tmae=0.287\n",
      "Epoch 82/100 \t lr=1.8e-04\t t=22s \tloss=0.216\tval_loss=0.277\tmae=0.280\n",
      "Epoch 83/100 \t lr=1.7e-04\t t=22s \tloss=0.213\tval_loss=0.278\tmae=0.281\n",
      "Epoch 84/100 \t lr=1.6e-04\t t=22s \tloss=0.210\tval_loss=0.279\tmae=0.283\n",
      "Epoch 85/100 \t lr=1.5e-04\t t=21s \tloss=0.208\tval_loss=0.271\tmae=0.275\n",
      "Epoch 86/100 \t lr=1.4e-04\t t=22s \tloss=0.207\tval_loss=0.270\tmae=0.273\n",
      "Epoch 87/100 \t lr=1.3e-04\t t=22s \tloss=0.206\tval_loss=0.270\tmae=0.274\n",
      "Epoch 88/100 \t lr=1.2e-04\t t=22s \tloss=0.203\tval_loss=0.268\tmae=0.271\n",
      "Epoch 89/100 \t lr=1.1e-04\t t=22s \tloss=0.201\tval_loss=0.268\tmae=0.271\n",
      "Epoch 90/100 \t lr=1.0e-04\t t=22s \tloss=0.198\tval_loss=0.266\tmae=0.269\n",
      "Epoch 91/100 \t lr=9.0e-05\t t=22s \tloss=0.198\tval_loss=0.267\tmae=0.270\n",
      "Epoch 92/100 \t lr=8.0e-05\t t=22s \tloss=0.195\tval_loss=0.265\tmae=0.268\n",
      "Epoch 93/100 \t lr=7.0e-05\t t=22s \tloss=0.192\tval_loss=0.267\tmae=0.270\n",
      "Epoch 94/100 \t lr=6.0e-05\t t=22s \tloss=0.192\tval_loss=0.265\tmae=0.269\n",
      "Epoch 95/100 \t lr=5.0e-05\t t=22s \tloss=0.190\tval_loss=0.262\tmae=0.265\n",
      "Epoch 96/100 \t lr=4.0e-05\t t=22s \tloss=0.188\tval_loss=0.262\tmae=0.265\n",
      "Epoch 97/100 \t lr=3.0e-05\t t=22s \tloss=0.187\tval_loss=0.261\tmae=0.264\n",
      "Epoch 98/100 \t lr=2.0e-05\t t=22s \tloss=0.185\tval_loss=0.260\tmae=0.263\n",
      "Epoch 99/100 \t lr=1.0e-05\t t=22s \tloss=0.184\tval_loss=0.260\tmae=0.263\n",
      "Epoch 100/100 \t lr=0.0e+00\t t=22s \tloss=0.182\tval_loss=0.260\tmae=0.263\n",
      "\n",
      " -> Saving weights to LSTM_6.pt\n",
      "\n",
      "\n",
      " -> CV MAE : 0.256\n"
     ]
    }
   ],
   "source": [
    "pred_oof, pred_test = k_fold(\n",
    "    Config, \n",
    "    train_df,\n",
    "    test_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-18T12:31:20.685458Z",
     "iopub.status.idle": "2021-10-18T12:31:20.685773Z",
     "shell.execute_reply": "2021-10-18T12:31:20.685631Z",
     "shell.execute_reply.started": "2021-10-18T12:31:20.685611Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./vpp_data/sample_submission.csv')\n",
    "sub['pressure'] = pred_test\n",
    "sub.to_csv('./vpp_data/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m58"
  },
  "kernelspec": {
   "display_name": "Python [conda env:camembert]",
   "language": "python",
   "name": "conda-env-camembert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
